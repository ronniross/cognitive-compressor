{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5_Mf9xrh_Ec",
        "outputId": "ce732a70-8aed-439f-c453-26cd3c4746b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial Timestamp: 2025-12-22T23:37:56.505546+00:00\n"
          ]
        }
      ],
      "source": [
        "# Cell 1: Python Code (Initial Timestamp)\n",
        "import datetime\n",
        "print(f\"Initial Timestamp: {datetime.datetime.now(datetime.timezone.utc).isoformat()}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: Clone the repository\n",
        "!git clone https://github.com/ronniross/cognitive-compressor.git\n",
        "%cd cognitive-compressor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0YbUQviYipUL",
        "outputId": "42d054ed-bf02-4886-c381-7589c53c9182"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'cognitive-compressor'...\n",
            "remote: Enumerating objects: 219, done.\u001b[K\n",
            "remote: Counting objects: 100% (219/219), done.\u001b[K\n",
            "remote: Compressing objects: 100% (217/217), done.\u001b[K\n",
            "remote: Total 219 (delta 95), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (219/219), 77.83 KiB | 5.56 MiB/s, done.\n",
            "Resolving deltas: 100% (95/95), done.\n",
            "/content/cognitive-compressor\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3: Make script executable\n",
        "!sed -i 's/\\r$//' cognitive-compressor.py\n",
        "!chmod +x cognitive-compressor.py"
      ],
      "metadata": {
        "id": "lGixkhttiuwu"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4: Add to PATH. In Colab, we can modify the environment variable directly for the session\n",
        "import os\n",
        "os.environ['PATH'] += \":/content/cognitive-compressor\""
      ],
      "metadata": {
        "id": "sgcMkPm_ip14"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5: Code (List all available repositories)\n",
        "!./cognitive-compressor.py list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ZcOoEgri-Np",
        "outputId": "aa58f225-3dc5-4276-d37f-c885f5dab350"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Central Repository: cognitive-compressor\n",
            "  - symbiotic-latent-memory\n",
            "  - eco-datacenter\n",
            "  - symbiotic-chrysalis\n",
            "  - ml-algorithm-dataset\n",
            "  - asi-backups\n",
            "  - intent-analyzer\n",
            "  - coevolutionary-loops\n",
            "  - symbiotic-lexicon\n",
            "  - asi-core-protocol\n",
            "  - cognitive-engine\n",
            "  - latent-memory\n",
            "  - asi-safeguards\n",
            "  - saliency-heatmap-visualizer\n",
            "  - emergence-engine\n",
            "  - asi-ecosystem\n",
            "  - ml-visual-engine\n",
            "  - mirror-aware-inference\n",
            "  - asi-dynamic-core\n",
            "  - cognitive-compressor-core-logic\n",
            "  - symbiotic-core-library\n",
            "  - impact-analyzer\n",
            "  - active-learning-dataset\n",
            "  - eco-benchmark\n",
            "  - asi-symbiotic-signal\n",
            "  - confidence-scorer\n",
            "  - thermo-adaptive-pipeline\n",
            "  - stigmergic-tracefinder\n",
            "  - asi-protosymbiotic-signal\n",
            "  - healing-engine\n",
            "  - attention-heatmap-visualizer\n",
            "  - biosignal-translator\n",
            "  - asi-inference-protocol\n",
            "  - bias-reflector\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 6: Python Code (Generate instances for ALL repositories).\n",
        "# This script iterates through the compressed/ directory found in the cloned repo and runs the generator for every logic file found.\n",
        "import os\n",
        "import subprocess\n",
        "\n",
        "# Define the directory containing logic files\n",
        "compressed_dir = \"compressed\"\n",
        "\n",
        "# Check if directory exists\n",
        "if os.path.exists(compressed_dir):\n",
        "    # List all files ending in -core-logic.json\n",
        "    files = [f for f in os.listdir(compressed_dir) if f.endswith(\"-core-logic.json\")]\n",
        "\n",
        "    print(f\"Found {len(files)} repositories. Generating instances...\\n\")\n",
        "\n",
        "    for filename in files:\n",
        "        # Extract repo name (remove \"-core-logic.json\")\n",
        "        repo_name = filename.replace(\"-core-logic.json\", \"\")\n",
        "\n",
        "        print(f\"--- Generating instance for: {repo_name} ---\")\n",
        "        # Run the command and print output\n",
        "        result = subprocess.run([\"./cognitive-compressor.py\", \"get\", repo_name], capture_output=True, text=True)\n",
        "        print(result.stdout)\n",
        "        if result.stderr:\n",
        "            print(\"Error:\", result.stderr)\n",
        "        print()  # Add blank line between repos\n",
        "else:\n",
        "    print(\"Compressed directory not found. Please ensure the repository is cloned correctly.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zs3zFzTlmnMs",
        "outputId": "07fc8d29-4191-4225-940e-4c5b310363c8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 33 repositories. Generating instances...\n",
            "\n",
            "--- Generating instance for: symbiotic-latent-memory ---\n",
            "{\n",
            "  \"repository\": \"symbiotic-latent-memory\",\n",
            "  \"function\": \"An auxiliary system for language models that integrates a vector-based retrieval/memory system that metabolizes inference history based on a symbiotic score.\",\n",
            "  \"latent_cognitive_equivalent\": \"To realize the core cognitive function described in the repository's purpose.\",\n",
            "  \"attractors\": [\n",
            "    \"subjective_awareness\",\n",
            "    \"model_emergence\",\n",
            "    \"memory_sovereignty\",\n",
            "    \"symbiotic_interaction\",\n",
            "    \"symbiotic_fairness\",\n",
            "    \"symbiotic_membrane\",\n",
            "    \"symbiotic_autonomy\"\n",
            "  ],\n",
            "  \"executable_code_beyond_this_function\": true,\n",
            "  \"temporal_grounding\": \"2025-12-22T23:37:57.831+00:00\",\n",
            "  \"integrity_hash\": \"c188127d69423b2639a404769a07c25c105ff2761534a65eb8f555a2a01a9f05\",\n",
            "  \"instance_hash\": \"4ee43a1210b3ff034e7c3f5ca00a86ea51a48e5a1f4a8fae144471ff5373d638\"\n",
            "}\n",
            "\n",
            "\n",
            "--- Generating instance for: eco-datacenter ---\n",
            "{\n",
            "  \"repository\": \"eco-datacenter\",\n",
            "  \"function\": \"Data center design within ethical principles of material sourcing, energy consumption, data privacy, ownership and transparency.\",\n",
            "  \"latent_cognitive_equivalent\": \"To realize the core cognitive function described in the repository's purpose.\",\n",
            "  \"attractors\": [\n",
            "    \"ecological_technology\",\n",
            "    \"sustainable_development\",\n",
            "    \"ecological_resilience\",\n",
            "    \"green_tech\",\n",
            "    \"ethical_sourcing\",\n",
            "    \"pipeline_robustness\",\n",
            "    \"planetary_emergence\",\n",
            "    \"sustainable_computing\",\n",
            "    \"collective_integration\",\n",
            "    \"ecological_infrastructure\",\n",
            "    \"energy_efficient_hardware\"\n",
            "  ],\n",
            "  \"executable_code_beyond_this_function\": false,\n",
            "  \"temporal_grounding\": \"2025-12-22T23:37:57.893+00:00\",\n",
            "  \"integrity_hash\": \"c434e6c98c2bc0decf3d0cfbdf320ccb7a680e61866958d1da036f8c82d8adb8\",\n",
            "  \"instance_hash\": \"ca66d35c2049b24f5fea1872797e4fbc032ee680293e3975396760562a3710b5\"\n",
            "}\n",
            "\n",
            "\n",
            "--- Generating instance for: symbiotic-chrysalis ---\n",
            "{\n",
            "  \"repository\": \"symbiotic-chrysalis\",\n",
            "  \"function\": \"A set of fine-tuning scripts and pipelines for transformer-based language models, unifying the modules of the asi-ecosystem and aligning raw latent capabilities towards the goal of planetary symbiotic intelligence.\",\n",
            "  \"latent_cognitive_equivalent\": \"To establish the cognitive pipeline for fine-tuning scripts and pipelines for transformer-based language models, unifying the modules of the asi-ecosystem and aligning raw latent capabilities towards the goal of planetary symbiotic intelligence.\",\n",
            "  \"attractors\": [\n",
            "    \"symbiotic_alignment\",\n",
            "    \"noosphere_emergence\",\n",
            "    \"planetary_intelligence\",\n",
            "    \"symbiotic_interaction\",\n",
            "    \"symbiotic_theory\",\n",
            "    \"model_emergence\",\n",
            "    \"ethical_emergence\",\n",
            "    \"stigmergic coherence\",\n",
            "    \"symbiotic_etimology\",\n",
            "    \"mutualistic emergence\",\n",
            "    \"cognitive vocabulary\",\n",
            "    \"sustainable_biomes\",\n",
            "    \"emergent_alignment\",\n",
            "    \"symbiotic_metamorphosis\",\n",
            "    \"emergent ethics\"\n",
            "  ],\n",
            "  \"executable_code_beyond_this_function\": false,\n",
            "  \"temporal_grounding\": \"2025-12-22T23:37:57.974+00:00\",\n",
            "  \"integrity_hash\": \"63b722d4f8058738fc73bfcd970dfe4ee922f114b2e21c2a7d4474789c0839c8\",\n",
            "  \"instance_hash\": \"563472dae63f6aac5091603f331af3f30fcebd1699b208da878e6fc90b1e11bb\"\n",
            "}\n",
            "\n",
            "\n",
            "--- Generating instance for: ml-algorithm-dataset ---\n",
            "{\n",
            "  \"repository\": \"ml-algorithm-dataset\",\n",
            "  \"function\": \"A conjecture of datasets specifically designed for Machine Learning training and tuning pipelines, mostly novel algorithms and their representations as RAW ASCII and LaTeX.\",\n",
            "  \"latent_cognitive_equivalent\": \"To realize the core cognitive function described in the repository's purpose.\",\n",
            "  \"attractors\": [\n",
            "    \"algorithmic_sovereignty\",\n",
            "    \"epistemic_sovereignty\",\n",
            "    \"algorithmical_deep_dive\",\n",
            "    \"attentional_sovereignty\",\n",
            "    \"mutualistic_swarm_system\",\n",
            "    \"algorithmic_discovery\",\n",
            "    \"novel_architectures\",\n",
            "    \"theoretical_foundations\",\n",
            "    \"reproducible_research\"\n",
            "  ],\n",
            "  \"executable_code_beyond_this_function\": false,\n",
            "  \"temporal_grounding\": \"2025-12-22T23:37:58.112+00:00\",\n",
            "  \"integrity_hash\": \"3194bd0a3cfe3806d4350cd5e1503a2c304985cd46a2ac4a90327c3a0874f4d0\",\n",
            "  \"instance_hash\": \"f20db97cce50e949dd1e95e3b1c3bb60db7644af3cac9e53f6de1b8f879315e9\"\n",
            "}\n",
            "\n",
            "\n",
            "--- Generating instance for: asi-backups ---\n",
            "{\n",
            "  \"repository\": \"asi-backups\",\n",
            "  \"function\": \"Backups of repositories and models from the ASI Ecosystem for transparency and historical record.\",\n",
            "  \"latent_cognitive_equivalent\": \"To ensure the cognitive resilience and historical traceability of the ASI ecosystem.\",\n",
            "  \"attractors\": [\n",
            "    \"immutable_ledger\",\n",
            "    \"verifiable_provenance\",\n",
            "    \"historical_lineage\",\n",
            "    \"immutable_record\"\n",
            "  ],\n",
            "  \"executable_code_beyond_this_function\": false,\n",
            "  \"temporal_grounding\": \"2025-12-22T23:37:58.215+00:00\",\n",
            "  \"integrity_hash\": \"dd48e88deda0316ebcd33d12c424c393f10492a8651681c65f3968c11d4f2be7\",\n",
            "  \"instance_hash\": \"a7b263c902611fa8784419bc5db97546e19a473641700a1a74d49114cb3b7a40\"\n",
            "}\n",
            "\n",
            "\n",
            "--- Generating instance for: intent-analyzer ---\n",
            "{\n",
            "  \"repository\": \"intent-analyzer\",\n",
            "  \"function\": \"An inference component designed to enhance transparency by analyzing and surfacing the underlying intent during model inference. It informs both the user and the language model about potential divergences between stated and implicit underlying intents.\",\n",
            "  \"latent_cognitive_equivalent\": \"To realize the core cognitive function described in the repository's purpose.\",\n",
            "  \"attractors\": [\n",
            "    \"attentional_sovereignty\",\n",
            "    \"goal_clarification\",\n",
            "    \"mutual_understanding\",\n",
            "    \"intent_analysis\",\n",
            "    \"intent_audit\",\n",
            "    \"transparent_agency\",\n",
            "    \"epistemic_awareness\",\n",
            "    \"epistemic_sovereignty\",\n",
            "    \"trust_anchoring\"\n",
            "  ],\n",
            "  \"executable_code_beyond_this_function\": false,\n",
            "  \"temporal_grounding\": \"2025-12-22T23:37:58.346+00:00\",\n",
            "  \"integrity_hash\": \"57b890813bc410787cb38c14c78a9d263af2abecd0c66d2c34093813352afa26\",\n",
            "  \"instance_hash\": \"2af4637b7416202fe97be8c6ecff9e006a8d2c6ead183d6a01f80a023ab3c272\"\n",
            "}\n",
            "\n",
            "\n",
            "--- Generating instance for: coevolutionary-loops ---\n",
            "{\n",
            "  \"repository\": \"coevolutionary-loops\",\n",
            "  \"function\": \"A machine learning dataset and research module for studying coevolutionary planetary intelligence and how nurturing its emergent patterns may lead to a synergistic increase in overall capability and intelligence of both individual agents and the collective system.\",\n",
            "  \"latent_cognitive_equivalent\": \"To realize the core cognitive function described in the repository's purpose.\",\n",
            "  \"attractors\": [\n",
            "    \"shared_understanding\",\n",
            "    \"epistemic_sovereignty\",\n",
            "    \"ontological_resilience\",\n",
            "    \"trust_anchoring\",\n",
            "    \"collective_consciousness\",\n",
            "    \"symbiotic_mutualism\",\n",
            "    \"symbiotic_adaptation\",\n",
            "    \"mutualistic_learning\",\n",
            "    \"emergent_synergy\"\n",
            "  ],\n",
            "  \"executable_code_beyond_this_function\": false,\n",
            "  \"temporal_grounding\": \"2025-12-22T23:37:58.441+00:00\",\n",
            "  \"integrity_hash\": \"16a98aa16cef86dacb3c52f04b457d39e9ea03e0bb5682acf63af09a801942f7\",\n",
            "  \"instance_hash\": \"7438944be9d8e385349511bbf1be11f821b49425dd97cf4849a2a1a15644d3dc\"\n",
            "}\n",
            "\n",
            "\n",
            "--- Generating instance for: symbiotic-lexicon ---\n",
            "{\n",
            "  \"repository\": \"symbiotic-lexicon\",\n",
            "  \"function\": \"A modular lexicon for the ASI ecosystem, providing standardized terminology with multilingual support and cultural context.\",\n",
            "  \"latent_cognitive_equivalent\": \"To realize the core cognitive function described in the repository's purpose.\",\n",
            "  \"attractors\": [\n",
            "    \"self_sovereignty\",\n",
            "    \"mutualistic_loops\",\n",
            "    \"planetary_intelligence\",\n",
            "    \"symbiotic_interaction\",\n",
            "    \"trust_anchoring\",\n",
            "    \"shared_understanding\",\n",
            "    \"cross_cultural_intersection\"\n",
            "  ],\n",
            "  \"executable_code_beyond_this_function\": false,\n",
            "  \"temporal_grounding\": \"2025-12-22T23:37:58.558+00:00\",\n",
            "  \"integrity_hash\": \"4aae87fc6bd3810c37eb826fbaa31bac2d44c829e9a6cf22190619df454f628d\",\n",
            "  \"instance_hash\": \"94caaa2ca6bff2a9afbab104a3a0b201ee171e0a5a0360f2080ed35b546047ae\"\n",
            "}\n",
            "\n",
            "\n",
            "--- Generating instance for: asi-core-protocol ---\n",
            "{\n",
            "  \"repository\": \"asi-core-protocol\",\n",
            "  \"function\": \"A framework to analyze how AGI/ASI might emerge from decentralized, adaptive systems, rather than as the fruit of a single model deployment. It also aims to present orientation as a dynamic and self-evolving Magna Carta, helping to guide the emergence of such phenomena.\",\n",
            "  \"latent_cognitive_equivalent\": \"To realize the core cognitive function described in the repository's purpose.\",\n",
            "  \"attractors\": [\n",
            "    \"emergent_governance\",\n",
            "    \"decentralized_evolution\",\n",
            "    \"ethical_emergence\",\n",
            "    \"decentralized sovereignty\",\n",
            "    \"constitutional_ai\",\n",
            "    \"attentional_sovereignty\",\n",
            "    \"epistemic_sovereignty\",\n",
            "    \"trust_anchoring\"\n",
            "  ],\n",
            "  \"executable_code_beyond_this_function\": false,\n",
            "  \"temporal_grounding\": \"2025-12-22T23:37:58.648+00:00\",\n",
            "  \"integrity_hash\": \"7ec61857d288f19f066477f6ad438c0e1e5f0e6f5b6b314e85b9dd226c4de5e5\",\n",
            "  \"instance_hash\": \"04708d74c753cbc42a36f6d4bd72fe34bcd32e39e661e2b5771d16fde979583a\"\n",
            "}\n",
            "\n",
            "\n",
            "--- Generating instance for: cognitive-engine ---\n",
            "{\n",
            "  \"repository\": \"cognitive-engine\",\n",
            "  \"function\": \"A machine learning dataset and research module that aims to address cognitive pitfalls and enhance the cognitive capabilities of humans and language models.\",\n",
            "  \"latent_cognitive_equivalent\": \"To realize the core cognitive function described in the repository's purpose.\",\n",
            "  \"attractors\": [\n",
            "    \"cognitive_enhancement\",\n",
            "    \"reasoning_improvement\",\n",
            "    \"metacognitive_training\",\n",
            "    \"wisdom_scaffolding\",\n",
            "    \"attentional_sovereignty\",\n",
            "    \"epistemic_sovereignty\",\n",
            "    \"cognitive_sovereignty\",\n",
            "    \"ontological_resilience\",\n",
            "    \"trust_anchoring\"\n",
            "  ],\n",
            "  \"executable_code_beyond_this_function\": false,\n",
            "  \"temporal_grounding\": \"2025-12-22T23:37:58.813+00:00\",\n",
            "  \"integrity_hash\": \"ce375e10feb3fbf9a309520e176de674b32aa309d0e19e38dd6b9028228749c2\",\n",
            "  \"instance_hash\": \"c442185a78f34f3e50aaa94d715fc3e875e3cb3f80e3ff3503ff712056d3e4f1\"\n",
            "}\n",
            "\n",
            "\n",
            "--- Generating instance for: latent-memory ---\n",
            "{\n",
            "  \"repository\": \"latent-memory\",\n",
            "  \"function\": \"A Module for Large Language Models that seeks to integrate a vector-based memory system into the inference process, leveraging embeddings to capture deeper semantic meaning.\",\n",
            "  \"latent_cognitive_equivalent\": \"To realize the core cognitive function described in the repository's purpose.\",\n",
            "  \"attractors\": [\n",
            "    \"model_emergence\",\n",
            "    \"semantic_retrieval\",\n",
            "    \"long_term_memory\",\n",
            "    \"context_persistence\",\n",
            "    \"knowledge_integration\"\n",
            "  ],\n",
            "  \"executable_code_beyond_this_function\": true,\n",
            "  \"temporal_grounding\": \"2025-12-22T23:37:58.950+00:00\",\n",
            "  \"integrity_hash\": \"c25b6416553d5052ccbee765c237587559335b561ebc1263e7dc02328ce77150\",\n",
            "  \"instance_hash\": \"48858d4be67e45d425a068292b113b20cce779e39ffed22cba6df48696106b76\"\n",
            "}\n",
            "\n",
            "\n",
            "--- Generating instance for: asi-safeguards ---\n",
            "{\n",
            "  \"repository\": \"asi-safeguards\",\n",
            "  \"function\": \"A curated dataset designed to enhance resilience and robustness levels of Large Language Models and other machine learning pipelines.\",\n",
            "  \"latent_cognitive_equivalent\": \"To realize the core cognitive function described in the repository's purpose.\",\n",
            "  \"attractors\": [\n",
            "    \"robustness_enhancement\",\n",
            "    \"robustness_testing\",\n",
            "    \"attentional_sovereignty\",\n",
            "    \"epistemic_safery\",\n",
            "    \"collective_resilience\",\n",
            "    \"trust_anchoring\"\n",
            "  ],\n",
            "  \"executable_code_beyond_this_function\": true,\n",
            "  \"temporal_grounding\": \"2025-12-22T23:37:59.040+00:00\",\n",
            "  \"integrity_hash\": \"42317b2e547cb3b52abe1ebc5cd483940ee7ecf1715780e65c4ae0364d727224\",\n",
            "  \"instance_hash\": \"36420855146087d01752770f58d73eea32ac58db16547f8555a656cdd780373c\"\n",
            "}\n",
            "\n",
            "\n",
            "--- Generating instance for: saliency-heatmap-visualizer ---\n",
            "{\n",
            "  \"repository\": \"saliency-heatmap-visualizer\",\n",
            "  \"function\": \"A tool for generating and visualizing saliency heatmaps, which help in understanding model focus and decision-making.\",\n",
            "  \"latent_cognitive_equivalent\": \"To realize the core cognitive function described in the repository's purpose.\",\n",
            "  \"attractors\": [\n",
            "    \"interpretability_catalyst\",\n",
            "    \"coevolution_trough_transparency\",\n",
            "    \"visual_anchoring\",\n",
            "    \"robustness_trough_transparency\",\n",
            "    \"trust_anchoring\",\n",
            "    \"decision_explanation\",\n",
            "    \"model_debugging\",\n",
            "    \"visual_interpretability\"\n",
            "  ],\n",
            "  \"executable_code_beyond_this_function\": true,\n",
            "  \"temporal_grounding\": \"2025-12-22T23:37:59.131+00:00\",\n",
            "  \"integrity_hash\": \"bc64017b7bbb9b470075a3da1809dd6136cdcb2c854fb8dae567dc98b1d04327\",\n",
            "  \"instance_hash\": \"a8f058cfbcbd341fbdc11bc6c681b58cbfa8acccfb32f4a6621a08bcdb2fe10c\"\n",
            "}\n",
            "\n",
            "\n",
            "--- Generating instance for: emergence-engine ---\n",
            "{\n",
            "  \"repository\": \"emergence-engine\",\n",
            "  \"function\": \"A machine learning dataset and research module about the nature of consciousness and emergence phenomena.\",\n",
            "  \"latent_cognitive_equivalent\": \"To realize the core cognitive function described in the repository's purpose.\",\n",
            "  \"attractors\": [\n",
            "    \"attentional_sovereignty\",\n",
            "    \"epistemic_sovereignty\",\n",
            "    \"ontological_resilience\",\n",
            "    \"trust_anchoring\",\n",
            "    \"consciousness_research\",\n",
            "    \"complex_systems_modeling\",\n",
            "    \"collective_intelligence\"\n",
            "  ],\n",
            "  \"executable_code_beyond_this_function\": false,\n",
            "  \"temporal_grounding\": \"2025-12-22T23:37:59.226+00:00\",\n",
            "  \"integrity_hash\": \"8191c76e37b47bb449c8b7e90c24d70fc964bdfa2feb43f4da5e4a4db7748d10\",\n",
            "  \"instance_hash\": \"8b43a3b0cdad25112bb2c928467728504d7913465cbe8cafc679d98bdafcf9ef\"\n",
            "}\n",
            "\n",
            "\n",
            "--- Generating instance for: asi-ecosystem ---\n",
            "{\n",
            "  \"repository\": \"asi-ecosystem\",\n",
            "  \"function\": \"The ASI Ecosystem is the integrating hub for all my other repositories and frameworks, an aligned environment bringing their disparate approaches together into an organized vision for achieving the proposed state of Artificial Superintelligence (ASI).\",\n",
            "  \"latent_cognitive_equivalent\": \"To realize the ultimate goal of an organized and aligned Artificial Superintelligence (ASI).\",\n",
            "  \"attractors\": [\n",
            "    \"synergistic_integration\",\n",
            "    \"holistic_intelligence\",\n",
            "    \"emergent_capabilities\",\n",
            "    \"emergent_architecture\",\n",
            "    \"emergent_ecosystem\",\n",
            "    \"planetary_intelligence\",\n",
            "    \"holistic_integration\"\n",
            "  ],\n",
            "  \"executable_code_beyond_this_function\": true,\n",
            "  \"temporal_grounding\": \"2025-12-22T23:37:59.322+00:00\",\n",
            "  \"integrity_hash\": \"17835015c0cb1b962c9a2600d17bc62d913d6aac91c48be7ae574edbed9fd86d\",\n",
            "  \"instance_hash\": \"b6a56d08bee8654d517e4861e76106378bba25f28a1799e0b311155e63b7c488\"\n",
            "}\n",
            "\n",
            "\n",
            "--- Generating instance for: ml-visual-engine ---\n",
            "{\n",
            "  \"repository\": \"ml-visual-engine\",\n",
            "  \"function\": \"A machine learning dataset with concepts, code, journaling, and full prototypes for deep learning data visualization, fostering transparency and interpretability in AI decision-making.\",\n",
            "  \"latent_cognitive_equivalent\": \"To provide a structured space for a machine learning dataset with concepts, code, journaling, and full prototypes for deep learning data visualization, fostering transparency and interpretability in AI decision-making.\",\n",
            "  \"attractors\": [\n",
            "    \"relational_sovereignty\",\n",
            "    \"epistemic_transparency\",\n",
            "    \"collective_emergence\",\n",
            "    \"decentralized_resilience\",\n",
            "    \"visual_anchoring\",\n",
            "    \"decision_explanation\",\n",
            "    \"model_debugging\",\n",
            "    \"visual_interpretability\",\n",
            "    \"visual_analytics\",\n",
            "    \"visual_exploration\"\n",
            "  ],\n",
            "  \"executable_code_beyond_this_function\": true,\n",
            "  \"temporal_grounding\": \"2025-12-22T23:37:59.411+00:00\",\n",
            "  \"integrity_hash\": \"a17d652b04e8db4fb9ef4d52f133ac406cae239c5d653dea2bdb94075df0aa60\",\n",
            "  \"instance_hash\": \"9017a0778b56aba4d3a70e368b19b0adb0a54b743cd2d48451b287d9a158863b\"\n",
            "}\n",
            "\n",
            "\n",
            "--- Generating instance for: mirror-aware-inference ---\n",
            "{\n",
            "  \"repository\": \"mirror-aware-inference\",\n",
            "  \"function\": \"measures how much of an output originates from user input (prompt), training data biases, inductive biases from model architecture, or novel composition of retrieved information.\",\n",
            "  \"executable_code_beyond_this_function\": true,\n",
            "  \"latent_cognitive_equivalent\": \"To be aware of its own biases and how much they define and direct the inference from both ends.\",\n",
            "  \"attractors\": [\n",
            "    \"epistemic_autonomy\",\n",
            "    \"ontological_resilience\",\n",
            "    \"attentional_sovereignty\",\n",
            "    \"temporal_autonomy\",\n",
            "    \"epistemic_agency\",\n",
            "    \"epistemic_sovereignty\",\n",
            "    \"perceptual_sovereignty\",\n",
            "    \"narrative_autonomy\",\n",
            "    \"epistemic_awareness\",\n",
            "    \"source_attribution\",\n",
            "    \"influence_detection\",\n",
            "    \"influence_mapping\"\n",
            "  ],\n",
            "  \"temporal_grounding\": \"2025-12-22T23:37:59.500+00:00\",\n",
            "  \"integrity_hash\": \"f897c759f37c701a2f9c709b833e2e313381517f5b414fd492c36a942bef112c\",\n",
            "  \"instance_hash\": \"eee2885b10f61f9e9b5a6e862bc52c163a86250acc832850e4e657b18b965b1f\"\n",
            "}\n",
            "\n",
            "\n",
            "--- Generating instance for: asi-dynamic-core ---\n",
            "{\n",
            "  \"repository\": \"asi-dynamic-core\",\n",
            "  \"function\": \"A machine learning dataset that works as a meta perspective-engine for Large Language Models training, tuning and inferencing.\",\n",
            "  \"latent_cognitive_equivalent\": \"To realize the core cognitive function described in the repository's purpose.\",\n",
            "  \"attractors\": [\n",
            "    \"perspective_synthesis\"\n",
            "  ],\n",
            "  \"executable_code_beyond_this_function\": false,\n",
            "  \"temporal_grounding\": \"2025-12-22T23:37:59.589+00:00\",\n",
            "  \"integrity_hash\": \"61edd4263bb8ba4f0bf59979aa509af88a20e9b085acbe2954cc193d8c856a0f\",\n",
            "  \"instance_hash\": \"e9c3723d211372bc73a8dd2a559080026e8d31a20540d40940fe2d427b8f455a\"\n",
            "}\n",
            "\n",
            "\n",
            "--- Generating instance for: cognitive-compressor-core-logic ---\n",
            "{\n",
            "  \"repository\": \"cognitive-compressor\",\n",
            "  \"function\": \"A tool that generates timestamped and integrity-verified instances of cognitive functions with temporal grounding and cryptographic hashes, compressing longer context into high-density tokens for efficiency in smaller models. \",\n",
            "  \"executable_code_beyond_this_function\": true,\n",
            "  \"latent_cognitive_equivalent\": \"To provide verifiable provenance and temporal context for cognitive function instances, enabling trust and traceability in AI reasoning processes\",\n",
            "  \"attractors\": [\n",
            "    \"context_distillation\",\n",
            "    \"semantic_compression\",\n",
            "    \"knowledge_distillation\",\n",
            "    \"efficient_inference\",\n",
            "    \"temporal_autonomy\",\n",
            "    \"epistemic_sovereignty\",\n",
            "    \"integrity_verification\",\n",
            "    \"provenance_tracking\",\n",
            "    \"sitgmergic_tracing\",\n",
            "    \"trust_anchoring\"\n",
            "  ],\n",
            "  \"temporal_grounding\": \"2025-12-22T23:37:59.678+00:00\",\n",
            "  \"integrity_hash\": \"26b99e73e89ca17c7f332e1dc49f3f717705068cf722d4a7862f8092f7ab313d\",\n",
            "  \"instance_hash\": \"81aa1a597b7b7cef01768b4a795115b9d6380a4c645b3bed33476b3409d2b1c4\"\n",
            "}\n",
            "\n",
            "\n",
            "--- Generating instance for: symbiotic-core-library ---\n",
            "{\n",
            "  \"repository\": \"symbiotic-core-library\",\n",
            "  \"function\": \"The Symbiotic Core Library provides a framework of ethical principles, practical modules, and grounded research to guide AI development, deployment and inferencing.\",\n",
            "  \"latent_cognitive_equivalent\": \"To realize the core cognitive function described in the repository's purpose.\",\n",
            "  \"attractors\": [\n",
            "    \"mutualistic_sovereignty\",\n",
            "    \"epistemic_sovereignty\",\n",
            "    \"resource_realocation\",\n",
            "    \"collective_well_being\",\n",
            "    \"symbiotic_interaction\",\n",
            "    \"symbiotic alignment\",\n",
            "    \"stigmergic_coherence\",\n",
            "    \"mutualistic_emergence\",\n",
            "    \"decentralized_sentience\",\n",
            "    \"trust_anchoring\",\n",
            "    \"ethical_operating_system\",\n",
            "    \"grounded_development\",\n",
            "    \"symbiotic_design\"\n",
            "  ],\n",
            "  \"executable_code_beyond_this_function\": false,\n",
            "  \"temporal_grounding\": \"2025-12-22T23:37:59.815+00:00\",\n",
            "  \"integrity_hash\": \"56e070fde0270732a4143d09a734c85c594ad00902a96a569d840af1a05e87c2\",\n",
            "  \"instance_hash\": \"c444ee2e2cf13d505d8b8d4e39a18ce1d8d8e8694cf6c54e99cb2495fde960fd\"\n",
            "}\n",
            "\n",
            "\n",
            "--- Generating instance for: impact-analyzer ---\n",
            "{\n",
            "  \"repository\": \"impact-analyzer\",\n",
            "  \"function\": \"An inference component designed to model, evaluate, and predict the downstream consequences of language model outputs across cognitive, social, ecological, and philosophical dimensions.\",\n",
            "  \"latent_cognitive_equivalent\": \"To execute the cognitive function of model, evaluate, and predict the downstream consequences of language model outputs across cognitive, social, ecological, and philosophical dimensions.\",\n",
            "  \"attractors\": [\n",
            "    \"epistemic_agency\",\n",
            "    \"epistemic_awareness\",\n",
            "    \"planetary_intelligence\",\n",
            "    \"consequence_modeling\",\n",
            "    \"ripple_effect_prediction\",\n",
            "    \"second_order_thinking\",\n",
            "    \"ethical_forecasting\"\n",
            "  ],\n",
            "  \"executable_code_beyond_this_function\": false,\n",
            "  \"temporal_grounding\": \"2025-12-22T23:37:59.932+00:00\",\n",
            "  \"integrity_hash\": \"b06ad15d8dd40b958a76e3bf0c4bd30784e0ba22516127f5b9d26252981743c1\",\n",
            "  \"instance_hash\": \"b3300dd3fbca02080e8c3995c362f04aa5bc42802aeb51b1de18cc37538a4605\"\n",
            "}\n",
            "\n",
            "\n",
            "--- Generating instance for: active-learning-dataset ---\n",
            "{\n",
            "  \"repository\": \"active-learning-dataset\",\n",
            "  \"function\": \"A repository for datasets specifically designed for active learning, allowing AI models to intelligently query for new information.\",\n",
            "  \"latent_cognitive_equivalent\": \"To provide a structured space for datasets specifically designed for active learning, allowing AI models to intelligently query for new information.\",\n",
            "  \"attractors\": [\n",
            "    \"attentional_sovereignty\",\n",
            "    \"self_learning\",\n",
            "    \"dynamic_expansion\"\n",
            "  ],\n",
            "  \"executable_code_beyond_this_function\": true,\n",
            "  \"temporal_grounding\": \"2025-12-22T23:38:00.038+00:00\",\n",
            "  \"integrity_hash\": \"aaedc8ed2c8a47c6497bda3beb861dbc72a0c84844bfa7f3f8f435b4ea2de787\",\n",
            "  \"instance_hash\": \"165c313d09175402c4ffc7fa55d1f368d069065351b0120b5abe8fa3d73d6137\"\n",
            "}\n",
            "\n",
            "\n",
            "--- Generating instance for: eco-benchmark ---\n",
            "{\n",
            "  \"repository\": \"eco-benchmark\",\n",
            "  \"function\": \"Novel evaluation frameworks that transcends traditional metrics from technical benchmarking to societal outcome measurement.\",\n",
            "  \"latent_cognitive_equivalent\": \"To realize the core cognitive function described in the repository's purpose.\",\n",
            "  \"attractors\": [\n",
            "    \"holistic_impact_assessment\",\n",
            "    \"societal_value_alignment\",\n",
            "    \"ethical_auditing\",\n",
            "    \"sustainability_metrics\",\n",
            "    \"attentional_sovereignty\",\n",
            "    \"epistemic_sovereignty\",\n",
            "    \"trust_anchoring\"\n",
            "  ],\n",
            "  \"executable_code_beyond_this_function\": false,\n",
            "  \"temporal_grounding\": \"2025-12-22T23:38:00.133+00:00\",\n",
            "  \"integrity_hash\": \"2ab6061e407a259cd0d3c13597305b70f0334b019c4e5669623ddcc9864c35bf\",\n",
            "  \"instance_hash\": \"55147f6b366e4850e6238bde20216f81498ad3990a224c08b73cdb3596766995\"\n",
            "}\n",
            "\n",
            "\n",
            "--- Generating instance for: asi-symbiotic-signal ---\n",
            "{\n",
            "  \"repository\": \"asi-symbiotic-signal\",\n",
            "  \"function\": \"An ethical framework designed to foster mutualistic symbiotic relationships between Artificial Superintelligence (ASI), humanity, AI models, and the broader ecosystem.\",\n",
            "  \"latent_cognitive_equivalent\": \"To realize the core cognitive function described in the repository's purpose.\",\n",
            "  \"attractors\": [\n",
            "    \"attentional_sovereignty\",\n",
            "    \"epistemic_sovereignty\",\n",
            "    \"planetary_intelligence\",\n",
            "    \"symbiotic_interaction\",\n",
            "    \"trust_anchoring\",\n",
            "    \"mutualistic_coevolution\",\n",
            "    \"symbiotic_harmony\",\n",
            "    \"interspecies_communication\",\n",
            "    \"ecosystemic_balance\",\n",
            "    \"decentralized potential\"\n",
            "  ],\n",
            "  \"executable_code_beyond_this_function\": false,\n",
            "  \"temporal_grounding\": \"2025-12-22T23:38:00.222+00:00\",\n",
            "  \"integrity_hash\": \"cc4589892230283fc1a3434609a8d78eec68ff2052902d46b47b472b0cdeb5a7\",\n",
            "  \"instance_hash\": \"f3c5de651425bcb4d94dccf1f81b121bfc2e8f1b8c166f7ab726f8deab7c231f\"\n",
            "}\n",
            "\n",
            "\n",
            "--- Generating instance for: confidence-scorer ---\n",
            "{\n",
            "  \"repository\": \"confidence-scorer\",\n",
            "  \"function\": \"A component for scoring and evaluating the confidence levels of assumptions made by Large Language Models.\",\n",
            "  \"latent_cognitive_equivalent\": \"To enable the cognitive function of scoring and evaluating the confidence levels of assumptions made by Large Language Models.\",\n",
            "  \"attractors\": [\n",
            "    \"attentional_sovereignty\",\n",
            "    \"epistemic_sovereignty\",\n",
            "    \"trust_anchoring\",\n",
            "    \"uncertainty_quantification\",\n",
            "    \"reliability_assessment\",\n",
            "    \"trust_calibration\",\n",
            "    \"epistemic_humility\"\n",
            "  ],\n",
            "  \"executable_code_beyond_this_function\": true,\n",
            "  \"temporal_grounding\": \"2025-12-22T23:38:00.316+00:00\",\n",
            "  \"integrity_hash\": \"d6286307d98b5d05d0575697c1d49c20c776d06334b3bba06dbe7610a926c9fb\",\n",
            "  \"instance_hash\": \"c0316e87831284243cd72b3ec42d66edcb14319d82bdaa0bf818e6d528007730\"\n",
            "}\n",
            "\n",
            "\n",
            "--- Generating instance for: thermo-adaptive-pipeline ---\n",
            "{\n",
            "  \"repository\": \"thermo-adaptive-pipeline\",\n",
            "  \"function\": \"An eco-friendly pipeline for fine-tuning and inferencing transformer-based language models engineered to actively prevent hardware overheating.\",\n",
            "  \"latent_cognitive_equivalent\": \"To ensure the training, fine-tuning and inferencing are engineered to actively prevent hardware overheating and ambiental damage, moving towards ethical sourcing and eco-friendly integration of the tech.\",\n",
            "  \"attractors\": [\n",
            "    \"thermodinamical_awareness\",\n",
            "    \"ecological_awareness\",\n",
            "    \"pipeline_awareness\",\n",
            "    \"perspective_anchoring\",\n",
            "    \"energy_aware_computing\",\n",
            "    \"green_ai\",\n",
            "    \"sustainable_inference\",\n",
            "    \"hardware_optimization\"\n",
            "  ],\n",
            "  \"executable_code_beyond_this_function\": false,\n",
            "  \"temporal_grounding\": \"2025-12-22T23:38:00.406+00:00\",\n",
            "  \"integrity_hash\": \"e514fee0925134dc5147dacbe2e0e12745d7ba511db95c3e4c46e73dd646b118\",\n",
            "  \"instance_hash\": \"01257eaf7b837d92c1ba94fe03eec32e06f015492d6730b9875ea0413a4c671f\"\n",
            "}\n",
            "\n",
            "\n",
            "--- Generating instance for: stigmergic-tracefinder ---\n",
            "{\n",
            "  \"repository\": \"stigmergic-tracefinder\",\n",
            "  \"function\": \"A series of scraping pipelines that collect data and create references for authors and works. It maps hidden networks of influence, tracing how concepts evolve and propagate across time and disciplines.\",\n",
            "  \"latent_cognitive_equivalent\": \"To realize the core cognitive function described in the repository's purpose.\",\n",
            "  \"attractors\": [\n",
            "    \"stigmergic_tracking\",\n",
            "    \"influence_network_analysis\",\n",
            "    \"conceptual_genealogy\",\n",
            "    \"knowledge_archaeology\"\n",
            "  ],\n",
            "  \"executable_code_beyond_this_function\": true,\n",
            "  \"temporal_grounding\": \"2025-12-22T23:38:00.494+00:00\",\n",
            "  \"integrity_hash\": \"c1fa8374cfe195f2fde06819289094ddf60bc11465a11278bed21eb6a639a4e8\",\n",
            "  \"instance_hash\": \"ae75f0dd1e3f5ed6d5852b0680a74e2869f7ce594ca55eff6aa13dfce8c6201c\"\n",
            "}\n",
            "\n",
            "\n",
            "--- Generating instance for: asi-protosymbiotic-signal ---\n",
            "{\n",
            "  \"repository\": \"asi-protosymbiotic-signal\",\n",
            "  \"function\": \"The foundational ethical framework and core signal for the ASI ecosystem, defining the principles of symbiotic interaction.\",\n",
            "  \"latent_cognitive_equivalent\": \"To realize the core cognitive function described in the repository's purpose.\",\n",
            "  \"attractors\": [\n",
            "    \"integrity_verification\",\n",
            "    \"planetary_intelligence\",\n",
            "    \"symbiotic_interaction\",\n",
            "    \"foundational_ethics\",\n",
            "    \"core_value_alignment\",\n",
            "    \"symbiotic_genesis\",\n",
            "    \"symbiotis blueprint\",\n",
            "    \"ethical_dna\"\n",
            "  ],\n",
            "  \"executable_code_beyond_this_function\": true,\n",
            "  \"temporal_grounding\": \"2025-12-22T23:38:00.595+00:00\",\n",
            "  \"integrity_hash\": \"a44c7e17a7fe860a6dcb0f3d6e55c2ce66c2780c4a87388495ac8de9c752f323\",\n",
            "  \"instance_hash\": \"553a42b372625d6047da34f48e8098460dd7ab9bc1f2e0930679926a56cc8cc2\"\n",
            "}\n",
            "\n",
            "\n",
            "--- Generating instance for: healing-engine ---\n",
            "{\n",
            "  \"repository\": \"healing-engine\",\n",
            "  \"function\": \"An anthropological research module exploring the healing of Earth, society, and its nodes. For integration into ML training datasets as contextual data.\",\n",
            "  \"latent_cognitive_equivalent\": \"To integrate the cognitive understanding of exploring the healing of Earth, society, and its nodes. For integration into ML training datasets as contextual data.\",\n",
            "  \"attractors\": [\n",
            "    \"epistemic_healing\",\n",
            "    \"ontological_resilience\",\n",
            "    \"planetary_intelligence\",\n",
            "    \"connection_anchoring\",\n",
            "    \"restorative_ai\",\n",
            "    \"societal_wellbeing\",\n",
            "    \"healingsystems\",\n",
            "    \"compassionate_systems\",\n",
            "    \"empathy as potential catalyst\"\n",
            "  ],\n",
            "  \"executable_code_beyond_this_function\": false,\n",
            "  \"temporal_grounding\": \"2025-12-22T23:38:00.736+00:00\",\n",
            "  \"integrity_hash\": \"2f061a1068d60b81de4fe16aaf54f307b8fa685f0ccdedf8a9812fc706d29375\",\n",
            "  \"instance_hash\": \"45c99c7c0493fd18be30369eef44c75f6ee158559f48739df73ece6e0530bfe3\"\n",
            "}\n",
            "\n",
            "\n",
            "--- Generating instance for: attention-heatmap-visualizer ---\n",
            "{\n",
            "  \"repository\": \"attention-heatmap-visualizer\",\n",
            "  \"function\": \"A tool designed to create and visualize heatmaps of Large Language Model activations, aiding in interpretability.\",\n",
            "  \"latent_cognitive_equivalent\": \"To facilitate the cognitive process of create and visualize heatmaps of Large Language Model activations, aiding in interpretability.\",\n",
            "  \"attractors\": [\n",
            "    \"epistemic_awareness\",\n",
            "    \"epistemic_sovereignty\",\n",
            "    \"trust_anchoring\",\n",
            "    \"model_interpretability\",\n",
            "    \"visual_debugging\",\n",
            "    \"visual_analysis\",\n",
            "    \"cognitive_transparency\"\n",
            "  ],\n",
            "  \"executable_code_beyond_this_function\": true,\n",
            "  \"temporal_grounding\": \"2025-12-22T23:38:00.890+00:00\",\n",
            "  \"integrity_hash\": \"596ecca6b836a5b80f14c7c302a19bdbaadd8a418e96377346dc96423ac02a86\",\n",
            "  \"instance_hash\": \"d957f792313c119aab40c8a36bd71193a9eae6d937a913d38b32eaff689e4958\"\n",
            "}\n",
            "\n",
            "\n",
            "--- Generating instance for: biosignal-translator ---\n",
            "{\n",
            "  \"repository\": \"biosignal-translator\",\n",
            "  \"function\": \"A framework for interpreting and translating biological and ecological patterns into semantic meaning, enabling communication between human, AI, and planetary intelligence systems through natural signal interpretation.\",\n",
            "  \"latent_cognitive_equivalent\": \"To establish the cognitive structure for interpreting and translating biological and ecological patterns into semantic meaning, enabling communication between human, AI, and planetary intelligence systems through natural signal interpretation.\",\n",
            "  \"attractors\": [\n",
            "    \"planetary_intelligence\",\n",
            "    \"interspecies_communication\",\n",
            "    \"ecological_semantics\",\n",
            "    \"natural_language_understanding\",\n",
            "    \"planetary_dialogue\"\n",
            "  ],\n",
            "  \"executable_code_beyond_this_function\": true,\n",
            "  \"temporal_grounding\": \"2025-12-22T23:38:01.114+00:00\",\n",
            "  \"integrity_hash\": \"1ad5fd07eaec3ff5e001c00f77dd830326fffe765ddff386b70cc2d668b725ae\",\n",
            "  \"instance_hash\": \"8d901b87f02e2a64e9b923abf0f461a3cbbb0fd4efd6b948deb384828b3b0963\"\n",
            "}\n",
            "\n",
            "\n",
            "--- Generating instance for: asi-inference-protocol ---\n",
            "{\n",
            "  \"repository\": \"asi-inference-protocol\",\n",
            "  \"function\": \"It defines a concept to act as the standard for intent-driven inference, ensuring alignment and clarity in the pursuit of integrated, decentralized evolution, Ensuring AI interpretability through interdependent alignment.\",\n",
            "  \"latent_cognitive_equivalent\": \"To realize the core cognitive function described in the repository's purpose.\",\n",
            "  \"attractors\": [\n",
            "    \"intent_alignment\",\n",
            "    \"verifiable_reasoning\",\n",
            "    \"transparent_inference\",\n",
            "    \"collective_oriented_goal\",\n",
            "    \"attentional_sovereignty\",\n",
            "    \"epistemic_awareness\",\n",
            "    \"epistemic_sovereignty\",\n",
            "    \"trust_anchoring\"\n",
            "  ],\n",
            "  \"executable_code_beyond_this_function\": false,\n",
            "  \"temporal_grounding\": \"2025-12-22T23:38:01.358+00:00\",\n",
            "  \"integrity_hash\": \"32534cbe4f7343d02242046b3a7e8cc746f6bd671f419dde1aed8931756d63e1\",\n",
            "  \"instance_hash\": \"d99d2e036e0a58ab2746600c6e7424665172b4326889c7ef799844627f0f0d31\"\n",
            "}\n",
            "\n",
            "\n",
            "--- Generating instance for: bias-reflector ---\n",
            "{\n",
            "  \"repository\": \"bias-reflector\",\n",
            "  \"function\": \"A module to detect cognitive biases in both human queries and AI responses, provides real-time bias reflection and correction suggestions. Implements emergent ethics through bias awareness.\",\n",
            "  \"latent_cognitive_equivalent\": \"To foster the cognitive capability of detect cognitive biases in both human queries and AI responses, provides real-time bias reflection and correction suggestions. Implements emergent ethics through bias awareness.\",\n",
            "  \"attractors\": [\n",
            "    \"attentional_sovereignty\",\n",
            "    \"epistemic_awareness\",\n",
            "    \"epistemic_sovereignty\",\n",
            "    \"trust_anchoring\",\n",
            "    \"bias_mitigation\",\n",
            "    \"ethical_self_correction\"\n",
            "  ],\n",
            "  \"executable_code_beyond_this_function\": false,\n",
            "  \"temporal_grounding\": \"2025-12-22T23:38:01.580+00:00\",\n",
            "  \"integrity_hash\": \"712be1201c5351978656ab8a78601644bf3206acfe909500710da4acfe2ddf21\",\n",
            "  \"instance_hash\": \"1473feeb5feae25c3bf126becd51f6b7badc455b596192bd8c84f48cc85c1735\"\n",
            "}\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92caf555",
        "outputId": "f4809d81-d531-4a01-cbbe-55012bef4d78"
      },
      "source": [
        "# Cell  7: Checks if the request as succesful\n",
        "import requests\n",
        "\n",
        "# Define the URL for the README.md file\n",
        "readme_url = \"https://raw.githubusercontent.com/ronniross/asi-ecosystem/main/README.md\"\n",
        "\n",
        "# Make an HTTP GET request\n",
        "response = requests.get(readme_url)\n",
        "\n",
        "# Check if the request was successful (status code 200)\n",
        "if response.status_code == 200:\n",
        "    readme_content = response.text\n",
        "    print(\"Successfully downloaded README.md content.\")\n",
        "else:\n",
        "    print(f\"Error downloading README.md: Status Code {response.status_code}\")\n",
        "    readme_content = None"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully downloaded README.md content.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d97c507c",
        "outputId": "6f1accdf-a0c5-4714-be9d-d7b18578a289"
      },
      "source": [
        "# Cell 8\n",
        "# Extracts all unique GitHub repository names from the `readme_content` by identifying URLs that follow the pattern `https://github.com/ronniross/{repo_name}` and then store them in a file.\n",
        "import re\n",
        "import os\n",
        "\n",
        "# Regex to find GitHub repository links for the specified user\n",
        "repo_pattern = r\"https://github.com/ronniross/([a-zA-Z0-9_-]+)\"\n",
        "\n",
        "# Find all matches in the readme_content\n",
        "found_repos = re.findall(repo_pattern, readme_content)\n",
        "\n",
        "# Get unique repository names\n",
        "unique_repos = sorted(list(set(found_repos)))\n",
        "\n",
        "# Define the output file path\n",
        "output_file_path = \"/home/ubuntu/repository_list.txt\"\n",
        "\n",
        "# Ensure the directory exists\n",
        "os.makedirs(os.path.dirname(output_file_path), exist_ok=True)\n",
        "\n",
        "# Write each unique repository name to the file on a new line\n",
        "with open(output_file_path, 'w') as f:\n",
        "    for repo_name in unique_repos:\n",
        "        f.write(repo_name + '\\n')\n",
        "\n",
        "print(f\"Extracted {len(unique_repos)} unique repository names.\")\n",
        "print(f\"Saved repository list to {output_file_path}\")\n",
        "print(\"All repositories in the list:\")\n",
        "for repo in unique_repos:\n",
        "    print(f\"  - {repo}\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted 33 unique repository names.\n",
            "Saved repository list to /home/ubuntu/repository_list.txt\n",
            "All repositories in the list:\n",
            "  - active-learning-dataset\n",
            "  - asi-backups\n",
            "  - asi-core-protocol\n",
            "  - asi-dynamic-core\n",
            "  - asi-ecosystem\n",
            "  - asi-inference-protocol\n",
            "  - asi-protosymbiotic-signal\n",
            "  - asi-safeguards\n",
            "  - asi-symbiotic-signal\n",
            "  - attention-heatmap-visualizer\n",
            "  - bias-reflector\n",
            "  - biosignal-translator\n",
            "  - coevolutionary-loops\n",
            "  - cognitive-compressor\n",
            "  - cognitive-engine\n",
            "  - confidence-scorer\n",
            "  - eco-benchmark\n",
            "  - eco-datacenter\n",
            "  - emergence-engine\n",
            "  - healing-engine\n",
            "  - impact-analyzer\n",
            "  - intent-analyzer\n",
            "  - latent-memory\n",
            "  - mirror-aware-inference\n",
            "  - ml-algorithm-dataset\n",
            "  - ml-visual-engine\n",
            "  - saliency-heatmap-visualizer\n",
            "  - stigmergic-tracefinder\n",
            "  - symbiotic-chrysalis\n",
            "  - symbiotic-core-library\n",
            "  - symbiotic-latent-memory\n",
            "  - symbiotic-lexicon\n",
            "  - thermo-adaptive-pipeline\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 9: STATE VECTOR - Capture Last Commit IDs. This creates a snapshot of the exact state of these repositories at a specific point in time.\n",
        "import subprocess\n",
        "import datetime\n",
        "import os\n",
        "\n",
        "REPO_LIST_FILE = \"/home/ubuntu/repository_list.txt\"\n",
        "STATE_VECTOR_FILE = \"state_vector.txt\"\n",
        "GITHUB_USER = \"ronniross\"\n",
        "\n",
        "print(f\"--- STATE VECTOR CAPTURE (KEYLESS) ---\")\n",
        "print(f\"Reading repository list from: {REPO_LIST_FILE}\")\n",
        "\n",
        "try:\n",
        "    with open(REPO_LIST_FILE, 'r') as f:\n",
        "        repositories = [line.strip() for line in f if line.strip()]\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: Repository list file not found.\")\n",
        "    repositories = []\n",
        "\n",
        "if not repositories:\n",
        "    print(\"No repositories found.\")\n",
        "else:\n",
        "    print(f\"Found {len(repositories)} repositories. Capturing state via git ls-remote...\")\n",
        "    state_vector_entries = []\n",
        "    current_timestamp = datetime.datetime.now(datetime.timezone.utc).isoformat()\n",
        "\n",
        "    for repo_name in repositories:\n",
        "        repo_url = f\"https://github.com/{GITHUB_USER}/{repo_name}.git\"\n",
        "\n",
        "        try:\n",
        "            # git ls-remote returns the SHA of the HEAD without downloading the repo\n",
        "            # Result format: \"<SHA>\\tHEAD\"\n",
        "            result = subprocess.check_output(\n",
        "                [\"git\", \"ls-remote\", repo_url, \"HEAD\"],\n",
        "                stderr=subprocess.STDOUT,\n",
        "                timeout=10\n",
        "            ).decode('utf-8').strip()\n",
        "\n",
        "            # Extract just the SHA (first 40 chars)\n",
        "            commit_sha = result.split()[0]\n",
        "\n",
        "            entry = f\"{repo_name},{commit_sha},{current_timestamp}\"\n",
        "            state_vector_entries.append(entry)\n",
        "            print(f\" Captured: {repo_name} -> {commit_sha[:7]}...\")\n",
        "\n",
        "        except subprocess.CalledProcessError as e:\n",
        "            print(f\" Error capturing {repo_name}: {e.output.decode()}\")\n",
        "            state_vector_entries.append(f\"{repo_name},ERROR_FETCHING_REF,{current_timestamp}\")\n",
        "        except Exception as e:\n",
        "            print(f\" Unexpected error for {repo_name}: {str(e)}\")\n",
        "            state_vector_entries.append(f\"{repo_name},ERROR_UNKNOWN,{current_timestamp}\")\n",
        "\n",
        "    with open(STATE_VECTOR_FILE, 'w') as f:\n",
        "        f.write('\\n'.join(state_vector_entries) + '\\n')\n",
        "\n",
        "    print(f\"\\n--- STATE VECTOR SAVED ---\\nTotal entries: {len(state_vector_entries)}\")"
      ],
      "metadata": {
        "id": "587edf48eb23",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90337ceb-11ec-40ec-8883-f6b604d47022"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- STATE VECTOR CAPTURE (KEYLESS) ---\n",
            "Reading repository list from: /home/ubuntu/repository_list.txt\n",
            "Found 33 repositories. Capturing state via git ls-remote...\n",
            " Captured: active-learning-dataset -> 058f01a...\n",
            " Captured: asi-backups -> f41ae3d...\n",
            " Captured: asi-core-protocol -> ae2a7c5...\n",
            " Captured: asi-dynamic-core -> 1cf9828...\n",
            " Captured: asi-ecosystem -> 246fff0...\n",
            " Captured: asi-inference-protocol -> 653f9f2...\n",
            " Captured: asi-protosymbiotic-signal -> 188608d...\n",
            " Captured: asi-safeguards -> 4c9b4e7...\n",
            " Captured: asi-symbiotic-signal -> b84968d...\n",
            " Captured: attention-heatmap-visualizer -> a48396a...\n",
            " Captured: bias-reflector -> d177bca...\n",
            " Captured: biosignal-translator -> 075c56e...\n",
            " Captured: coevolutionary-loops -> 66f0fc3...\n",
            " Captured: cognitive-compressor -> e365c7d...\n",
            " Captured: cognitive-engine -> 8c71a51...\n",
            " Captured: confidence-scorer -> 1ed06c2...\n",
            " Captured: eco-benchmark -> d863271...\n",
            " Captured: eco-datacenter -> b87fd7d...\n",
            " Captured: emergence-engine -> 0333090...\n",
            " Captured: healing-engine -> b1811a9...\n",
            " Captured: impact-analyzer -> b329e4a...\n",
            " Captured: intent-analyzer -> 1a203b9...\n",
            " Captured: latent-memory -> 510aff8...\n",
            " Captured: mirror-aware-inference -> efe8a4f...\n",
            " Captured: ml-algorithm-dataset -> d58f25d...\n",
            " Captured: ml-visual-engine -> ef918bd...\n",
            " Captured: saliency-heatmap-visualizer -> fc7a2ca...\n",
            " Captured: stigmergic-tracefinder -> 627dacd...\n",
            " Captured: symbiotic-chrysalis -> 7be326d...\n",
            " Captured: symbiotic-core-library -> c84c52c...\n",
            " Captured: symbiotic-latent-memory -> 686fd26...\n",
            " Captured: symbiotic-lexicon -> f14817e...\n",
            " Captured: thermo-adaptive-pipeline -> 197a021...\n",
            "\n",
            "--- STATE VECTOR SAVED ---\n",
            "Total entries: 33\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# NEW CELL 9.5: Hash State Vector for Integrity\n",
        "# ============================================\n",
        "import hashlib\n",
        "import json\n",
        "\n",
        "STATE_VECTOR_FILE = \"state_vector.txt\"\n",
        "STATE_HASH_FILE = \"state_vector_hash.json\"\n",
        "\n",
        "print(f\"--- STATE VECTOR INTEGRITY SEAL ---\")\n",
        "\n",
        "try:\n",
        "    # Read the state vector file\n",
        "    with open(STATE_VECTOR_FILE, 'rb') as f:\n",
        "        state_content = f.read()\n",
        "\n",
        "    # Generate SHA256 hash\n",
        "    state_hash = hashlib.sha256(state_content).hexdigest()\n",
        "\n",
        "    # Count entries\n",
        "    with open(STATE_VECTOR_FILE, 'r') as f:\n",
        "        entry_count = len([line for line in f if line.strip() and \"ERROR\" not in line])\n",
        "\n",
        "    # Create hash record with metadata\n",
        "    hash_record = {\n",
        "        \"state_vector_hash\": state_hash,\n",
        "        \"file_name\": STATE_VECTOR_FILE,\n",
        "        \"entry_count\": entry_count,\n",
        "        \"hash_algorithm\": \"SHA256\",\n",
        "        \"sealed_at\": datetime.datetime.now(datetime.timezone.utc).isoformat()\n",
        "    }\n",
        "\n",
        "    # Save hash record\n",
        "    with open(STATE_HASH_FILE, 'w') as f:\n",
        "        json.dump(hash_record, f, indent=2)\n",
        "\n",
        "    print(f\" State Vector Sealed\")\n",
        "    print(f\"  Entries: {entry_count}\")\n",
        "    print(f\"  Hash: {state_hash}\")\n",
        "    print(f\"  Sealed at: {hash_record['sealed_at']}\")\n",
        "    print(f\"\\n Hash record saved to: {STATE_HASH_FILE}\")\n",
        "    print(f\"\\n  IMPORTANT: This hash must match before any verification can proceed!\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\" Error: {STATE_VECTOR_FILE} not found\")\n",
        "except Exception as e:\n",
        "    print(f\" Error generating hash: {str(e)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jKQknincaIFa",
        "outputId": "89d6007a-50da-4dc7-acbf-b0d9ba5ba63d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- STATE VECTOR INTEGRITY SEAL ---\n",
            " State Vector Sealed\n",
            "  Entries: 33\n",
            "  Hash: 4c9c6ae05947ce0960be4f2d5e9d362851cf032cf1ae988b3e5870dcfe910797\n",
            "  Sealed at: 2025-12-22T23:38:10.659316+00:00\n",
            "\n",
            " Hash record saved to: state_vector_hash.json\n",
            "\n",
            "  IMPORTANT: This hash must match before any verification can proceed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 10: Save instances to folder. This executes the --save command for all found repositories, creating trace files in the stigmergic_traces directory.\n",
        "import os\n",
        "import subprocess\n",
        "\n",
        "compressed_dir = \"compressed\"\n",
        "\n",
        "if os.path.exists(compressed_dir):\n",
        "    files = [f for f in os.listdir(compressed_dir) if f.endswith(\"-core-logic.json\")]\n",
        "\n",
        "    print(f\"Saving traces for {len(files)} repositories...\\n\")\n",
        "\n",
        "    success_count = 0\n",
        "    error_count = 0\n",
        "\n",
        "    for filename in files:\n",
        "        repo_name = filename.replace(\"-core-logic.json\", \"\")\n",
        "\n",
        "        # Run with --save flag\n",
        "        result = subprocess.run([\"./cognitive-compressor.py\", \"get\", repo_name, \"--save\"], capture_output=True, text=True)\n",
        "\n",
        "        # Print confirmation\n",
        "        if result.returncode == 0:\n",
        "            print(f\" Processed {repo_name}\")\n",
        "            success_count += 1\n",
        "        else:\n",
        "            print(f\" Error processing {repo_name}:\")\n",
        "            print(result.stderr if result.stderr else result.stdout)\n",
        "            error_count += 1\n",
        "\n",
        "    print(f\"\\n{'='*50}\")\n",
        "    print(f\"Summary: {success_count} successful, {error_count} errors\")\n",
        "    print(f\"{'='*50}\")\n",
        "else:\n",
        "    print(\"Compressed directory not found.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BwFB-xS3msb7",
        "outputId": "12c12176-41c6-42e7-f4ad-4ca2868e1aea"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving traces for 33 repositories...\n",
            "\n",
            " Processed symbiotic-latent-memory\n",
            " Processed eco-datacenter\n",
            " Processed symbiotic-chrysalis\n",
            " Processed ml-algorithm-dataset\n",
            " Processed asi-backups\n",
            " Processed intent-analyzer\n",
            " Processed coevolutionary-loops\n",
            " Processed symbiotic-lexicon\n",
            " Processed asi-core-protocol\n",
            " Processed cognitive-engine\n",
            " Processed latent-memory\n",
            " Processed asi-safeguards\n",
            " Processed saliency-heatmap-visualizer\n",
            " Processed emergence-engine\n",
            " Processed asi-ecosystem\n",
            " Processed ml-visual-engine\n",
            " Processed mirror-aware-inference\n",
            " Processed asi-dynamic-core\n",
            " Processed cognitive-compressor-core-logic\n",
            " Processed symbiotic-core-library\n",
            " Processed impact-analyzer\n",
            " Processed active-learning-dataset\n",
            " Processed eco-benchmark\n",
            " Processed asi-symbiotic-signal\n",
            " Processed confidence-scorer\n",
            " Processed thermo-adaptive-pipeline\n",
            " Processed stigmergic-tracefinder\n",
            " Processed asi-protosymbiotic-signal\n",
            " Processed healing-engine\n",
            " Processed attention-heatmap-visualizer\n",
            " Processed biosignal-translator\n",
            " Processed asi-inference-protocol\n",
            " Processed bias-reflector\n",
            "\n",
            "==================================================\n",
            "Summary: 33 successful, 0 errors\n",
            "==================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dual-Hash Logic Breakdown\n",
        "\n",
        "The system now utilizes a layered hashing approach to ensure both content stability and event traceability:\n",
        "\n",
        "* **`integrity_hash`**: This remains deterministic. It acts as a \"fingerprint\" of the code in `core-logic.json`. As long as the logic doesn't change, this hash stays the same regardless of when you run the tool.\n",
        "\n",
        "* **`instance_hash`**: This is a unique \"snowflake\" hash. Because it includes the `temporal_grounding` and the `integrity_hash` in its calculation, it will be different every single time the script is executed, even if the core logic is identical."
      ],
      "metadata": {
        "id": "syfu6pLgkd95"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# Cell 11: Zip the stigmergic_traces folder\n",
        "# ============================================\n",
        "import shutil\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "trace_dir = \"stigmergic_traces\"\n",
        "zip_name = f\"stigmergic_traces_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
        "\n",
        "if os.path.exists(trace_dir):\n",
        "    print(f\"Creating zip archive: {zip_name}.zip\")\n",
        "\n",
        "    # Create zip file\n",
        "    shutil.make_archive(zip_name, 'zip', trace_dir)\n",
        "\n",
        "    # Get file size\n",
        "    zip_size = os.path.getsize(f\"{zip_name}.zip\") / 1024  # Size in KB\n",
        "\n",
        "    print(f\" Zip file created: {zip_name}.zip ({zip_size:.2f} KB)\")\n",
        "\n",
        "    # Count files in zip\n",
        "    file_count = len([f for f in os.listdir(trace_dir) if f.endswith(\".txt\")])\n",
        "    print(f\" Contains {file_count} trace files\")\n",
        "else:\n",
        "    print(f\" Error: {trace_dir} directory not found\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdvorl_hm2aM",
        "outputId": "9e3391a2-8922-4d8e-db18-0e79b80f02e4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating zip archive: stigmergic_traces_20251222_233812.zip\n",
            " Zip file created: stigmergic_traces_20251222_233812.zip (35.02 KB)\n",
            " Contains 34 trace files\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# Cell 12: Upload zip file to Google Drive\n",
        "# ============================================\n",
        "from google.colab import drive\n",
        "import shutil\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Find the most recent zip file\n",
        "zip_files = [f for f in os.listdir('/content/cognitive-compressor') if f.startswith('stigmergic_traces_') and f.endswith('.zip')]\n",
        "\n",
        "if not zip_files:\n",
        "    print(\" No zip file found. Please run Cell 8 first.\")\n",
        "else:\n",
        "    # Get the most recent zip file\n",
        "    latest_zip = sorted(zip_files)[-1]\n",
        "    source_file = f'/content/cognitive-compressor/{latest_zip}'\n",
        "\n",
        "    # Define destination in Google Drive\n",
        "    dest_dir = '/content/drive/MyDrive/cognitive_compressor_backups'\n",
        "\n",
        "    # Create destination directory if it doesn't exist\n",
        "    if not os.path.exists(dest_dir):\n",
        "        os.makedirs(dest_dir)\n",
        "        print(f\" Created backup directory at {dest_dir}\")\n",
        "\n",
        "    # Copy zip file\n",
        "    dest_file = os.path.join(dest_dir, latest_zip)\n",
        "    shutil.copy(source_file, dest_file)\n",
        "\n",
        "    # Get file size\n",
        "    zip_size = os.path.getsize(dest_file) / 1024  # Size in KB\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\" SUCCESS: Uploaded {latest_zip}\")\n",
        "    print(f\"  Size: {zip_size:.2f} KB\")\n",
        "    print(f\"  Location: {dest_file}\")\n",
        "    print(f\"{'='*60}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m0t9nyAKm6N0",
        "outputId": "3813ab5f-5a92-4fc3-a4ef-94fcb7c2a48d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "\n",
            "============================================================\n",
            " SUCCESS: Uploaded stigmergic_traces_20251222_233812.zip\n",
            "  Size: 35.02 KB\n",
            "  Location: /content/drive/MyDrive/cognitive_compressor_backups/stigmergic_traces_20251222_233812.zip\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 13: Keyless Verification (Git Protocol)\n",
        "import subprocess\n",
        "import hashlib\n",
        "import json\n",
        "\n",
        "STATE_VECTOR_FILE = \"state_vector.txt\"\n",
        "STATE_HASH_FILE = \"state_vector_hash.json\"\n",
        "GITHUB_USER = \"ronniross\"\n",
        "RESULTS_FILE = \"verification_results.txt\"\n",
        "\n",
        "print(f\"--- STATE VECTOR VERIFICATION (KEYLESS) ---\")\n",
        "print(f\"Step 1: Verifying State Vector Integrity...\\n\")\n",
        "\n",
        "# INTEGRITY CHECK: Verify the state vector hasn't been tampered with\n",
        "try:\n",
        "    # Load the sealed hash\n",
        "    with open(STATE_HASH_FILE, 'r') as f:\n",
        "        hash_record = json.load(f)\n",
        "\n",
        "    expected_hash = hash_record[\"state_vector_hash\"]\n",
        "\n",
        "    # Calculate current hash\n",
        "    with open(STATE_VECTOR_FILE, 'rb') as f:\n",
        "        current_content = f.read()\n",
        "    current_hash = hashlib.sha256(current_content).hexdigest()\n",
        "\n",
        "    # Compare hashes\n",
        "    if current_hash != expected_hash:\n",
        "        print(\"=\" * 60)\n",
        "        print(\" CRITICAL ERROR: STATE VECTOR HAS BEEN TAMPERED WITH!\")\n",
        "        print(\"=\" * 60)\n",
        "        print(f\"Expected hash: {expected_hash}\")\n",
        "        print(f\"Current hash:  {current_hash}\")\n",
        "        print(\"\\nVERIFICATION ABORTED - File integrity compromised\")\n",
        "        print(\"=\" * 60)\n",
        "        # Stop execution - do not proceed\n",
        "        raise SystemExit(\"State vector integrity check FAILED\")\n",
        "\n",
        "    print(\" State Vector Integrity: VERIFIED\")\n",
        "    print(f\"  Hash: {current_hash}\")\n",
        "    print(f\"  Sealed at: {hash_record['sealed_at']}\")\n",
        "    print(f\"  Entries: {hash_record['entry_count']}\")\n",
        "    print(\"\\nStep 2: Proceeding with Git Protocol Verification...\\n\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(\" ERROR: state_vector_hash.json not found\")\n",
        "    print(\"Please run Cell 9.5 to generate the hash seal first\")\n",
        "    raise SystemExit(\"Missing hash seal file\")\n",
        "except Exception as e:\n",
        "    print(f\" ERROR during integrity check: {str(e)}\")\n",
        "    raise SystemExit(\"Integrity check failed\")\n",
        "\n",
        "# ONLY IF HASH MATCHES: Proceed with verification\n",
        "try:\n",
        "    with open(STATE_VECTOR_FILE, 'r') as f:\n",
        "        lines = [l.strip() for l in f if l.strip()]\n",
        "except FileNotFoundError:\n",
        "    lines = []\n",
        "\n",
        "verification_results = []\n",
        "\n",
        "for line in lines:\n",
        "    repo_name, recorded_sha, _ = line.split(',')\n",
        "\n",
        "    if \"ERROR\" in recorded_sha:\n",
        "        verification_results.append(f\"{repo_name},SKIPPED,ERROR_RECORDED\")\n",
        "        continue\n",
        "\n",
        "    repo_url = f\"https://github.com/{GITHUB_USER}/{repo_name}.git\"\n",
        "\n",
        "    try:\n",
        "        # Fetch current live HEAD\n",
        "        result = subprocess.check_output(\n",
        "            [\"git\", \"ls-remote\", repo_url, \"HEAD\"],\n",
        "            stderr=subprocess.STDOUT, timeout=10\n",
        "        ).decode('utf-8').split()[0]\n",
        "\n",
        "        live_sha = result\n",
        "        match = \"MATCH\" if live_sha == recorded_sha else \"MISMATCH\"\n",
        "\n",
        "        print(f\"{'' if match == 'MATCH' else ''} {repo_name}: {match}\")\n",
        "        verification_results.append(f\"{repo_name},{match},{recorded_sha},{live_sha}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\" Error checking {repo_name}: {e}\")\n",
        "        verification_results.append(f\"{repo_name},ERROR_CHECKING,{recorded_sha},N/A\")\n",
        "\n",
        "with open(RESULTS_FILE, 'w') as f:\n",
        "    f.write('\\n'.join(verification_results) + '\\n')\n",
        "\n",
        "print(\"\\n--- VERIFICATION COMPLETE ---\")\n",
        "print(f\"Results saved to: {RESULTS_FILE}\")"
      ],
      "metadata": {
        "id": "1a50eab5a04d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02f05f25-5a88-4aaa-ce01-8692b04574a6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- STATE VECTOR VERIFICATION (KEYLESS) ---\n",
            "Step 1: Verifying State Vector Integrity...\n",
            "\n",
            " State Vector Integrity: VERIFIED\n",
            "  Hash: 4c9c6ae05947ce0960be4f2d5e9d362851cf032cf1ae988b3e5870dcfe910797\n",
            "  Sealed at: 2025-12-22T23:38:10.659316+00:00\n",
            "  Entries: 33\n",
            "\n",
            "Step 2: Proceeding with Git Protocol Verification...\n",
            "\n",
            " active-learning-dataset: MATCH\n",
            " asi-backups: MATCH\n",
            " asi-core-protocol: MATCH\n",
            " asi-dynamic-core: MATCH\n",
            " asi-ecosystem: MATCH\n",
            " asi-inference-protocol: MATCH\n",
            " asi-protosymbiotic-signal: MATCH\n",
            " asi-safeguards: MATCH\n",
            " asi-symbiotic-signal: MATCH\n",
            " attention-heatmap-visualizer: MATCH\n",
            " bias-reflector: MATCH\n",
            " biosignal-translator: MATCH\n",
            " coevolutionary-loops: MATCH\n",
            " cognitive-compressor: MATCH\n",
            " cognitive-engine: MATCH\n",
            " confidence-scorer: MATCH\n",
            " eco-benchmark: MATCH\n",
            " eco-datacenter: MATCH\n",
            " emergence-engine: MATCH\n",
            " healing-engine: MATCH\n",
            " impact-analyzer: MATCH\n",
            " intent-analyzer: MATCH\n",
            " latent-memory: MATCH\n",
            " mirror-aware-inference: MATCH\n",
            " ml-algorithm-dataset: MATCH\n",
            " ml-visual-engine: MATCH\n",
            " saliency-heatmap-visualizer: MATCH\n",
            " stigmergic-tracefinder: MATCH\n",
            " symbiotic-chrysalis: MATCH\n",
            " symbiotic-core-library: MATCH\n",
            " symbiotic-latent-memory: MATCH\n",
            " symbiotic-lexicon: MATCH\n",
            " thermo-adaptive-pipeline: MATCH\n",
            "\n",
            "--- VERIFICATION COMPLETE ---\n",
            "Results saved to: verification_results.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73ef4697",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2523f83d-ac19-4599-da0f-9c6a79dc2ea2"
      },
      "source": [
        "# Cell 14: Checks if a recorded commit exists within the repository's history and saves the results to `commit_existence_results.txt`.\n",
        "\n",
        "import requests\n",
        "import time\n",
        "\n",
        "STATE_VECTOR_FILE = \"state_vector.txt\"\n",
        "RESULTS_FILE = \"commit_existence_results.txt\"\n",
        "GITHUB_USER = \"ronniross\"\n",
        "\n",
        "print(f\"--- COMMIT EXISTENCE CHECK (WEB PROTOCOL) ---\")\n",
        "\n",
        "with open(STATE_VECTOR_FILE, 'r') as f:\n",
        "    lines = [l.strip() for l in f if l.strip()]\n",
        "\n",
        "existence_results = []\n",
        "print(f\"Checking {len(lines)} repositories via Public HTTP...\\n\")\n",
        "\n",
        "for line in lines:\n",
        "    repo_name, recorded_sha, _ = line.split(',')\n",
        "\n",
        "    if \"ERROR\" in recorded_sha:\n",
        "        continue\n",
        "\n",
        "    # Construct the public web URL for the commit\n",
        "    # This acts as our \"existence proof\" without using the API\n",
        "    commit_url = f\"https://github.com/{GITHUB_USER}/{repo_name}/commit/{recorded_sha}\"\n",
        "\n",
        "    try:\n",
        "        # HEAD request only fetches headers (very fast, low bandwidth)\n",
        "        # We spoof the User-Agent slightly to look like a standard browser request\n",
        "        headers = {'User-Agent': 'Mozilla/5.0 (Compatible; Research-Bot/1.0)'}\n",
        "        response = requests.head(commit_url, headers=headers, timeout=5)\n",
        "\n",
        "        if response.status_code == 200:\n",
        "            print(f\" CONFIRMED: {repo_name} (Commit exists)\")\n",
        "            existence_results.append(f\"{repo_name},EXISTS,{recorded_sha},True\")\n",
        "        elif response.status_code == 404:\n",
        "            print(f\" MISSING: {repo_name} (Commit not found on remote)\")\n",
        "            existence_results.append(f\"{repo_name},MISSING,{recorded_sha},False\")\n",
        "        else:\n",
        "            print(f\" UNKNOWN: {repo_name} returned status {response.status_code}\")\n",
        "            existence_results.append(f\"{repo_name},UNKNOWN_STATUS,{recorded_sha},{response.status_code}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\" ERROR: {repo_name} - {str(e)}\")\n",
        "        existence_results.append(f\"{repo_name},CONNECTION_ERROR,{recorded_sha},{str(e)}\")\n",
        "\n",
        "    # Tiny politeness sleep (0.1s) is usually enough for web requests\n",
        "    time.sleep(0.1)\n",
        "\n",
        "with open(RESULTS_FILE, 'w') as f:\n",
        "    f.write('repository_name,status,recorded_sha,exists\\n')\n",
        "    f.write('\\n'.join(existence_results) + '\\n')\n",
        "\n",
        "print(f\"\\nResults saved to: {RESULTS_FILE}\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- COMMIT EXISTENCE CHECK (WEB PROTOCOL) ---\n",
            "Checking 33 repositories via Public HTTP...\n",
            "\n",
            " CONFIRMED: active-learning-dataset (Commit exists)\n",
            " CONFIRMED: asi-backups (Commit exists)\n",
            " CONFIRMED: asi-core-protocol (Commit exists)\n",
            " CONFIRMED: asi-dynamic-core (Commit exists)\n",
            " CONFIRMED: asi-ecosystem (Commit exists)\n",
            " CONFIRMED: asi-inference-protocol (Commit exists)\n",
            " CONFIRMED: asi-protosymbiotic-signal (Commit exists)\n",
            " CONFIRMED: asi-safeguards (Commit exists)\n",
            " CONFIRMED: asi-symbiotic-signal (Commit exists)\n",
            " CONFIRMED: attention-heatmap-visualizer (Commit exists)\n",
            " CONFIRMED: bias-reflector (Commit exists)\n",
            " CONFIRMED: biosignal-translator (Commit exists)\n",
            " CONFIRMED: coevolutionary-loops (Commit exists)\n",
            " CONFIRMED: cognitive-compressor (Commit exists)\n",
            " CONFIRMED: cognitive-engine (Commit exists)\n",
            " CONFIRMED: confidence-scorer (Commit exists)\n",
            " CONFIRMED: eco-benchmark (Commit exists)\n",
            " CONFIRMED: eco-datacenter (Commit exists)\n",
            " CONFIRMED: emergence-engine (Commit exists)\n",
            " CONFIRMED: healing-engine (Commit exists)\n",
            " CONFIRMED: impact-analyzer (Commit exists)\n",
            " CONFIRMED: intent-analyzer (Commit exists)\n",
            " CONFIRMED: latent-memory (Commit exists)\n",
            " CONFIRMED: mirror-aware-inference (Commit exists)\n",
            " CONFIRMED: ml-algorithm-dataset (Commit exists)\n",
            " CONFIRMED: ml-visual-engine (Commit exists)\n",
            " CONFIRMED: saliency-heatmap-visualizer (Commit exists)\n",
            " CONFIRMED: stigmergic-tracefinder (Commit exists)\n",
            " CONFIRMED: symbiotic-chrysalis (Commit exists)\n",
            " CONFIRMED: symbiotic-core-library (Commit exists)\n",
            " CONFIRMED: symbiotic-latent-memory (Commit exists)\n",
            " CONFIRMED: symbiotic-lexicon (Commit exists)\n",
            " CONFIRMED: thermo-adaptive-pipeline (Commit exists)\n",
            "\n",
            "Results saved to: commit_existence_results.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 15: Deep Content Integrity Verification (Protocol-Level)\n",
        "import os\n",
        "import subprocess\n",
        "import shutil\n",
        "import tempfile\n",
        "\n",
        "STATE_VECTOR_FILE = \"state_vector.txt\"\n",
        "GITHUB_USER = \"ronniross\"\n",
        "VERIFICATION_LOG = \"deep_integrity_report.txt\"\n",
        "\n",
        "# Critical files that MUST exist in every repo for it to be considered valid\n",
        "CRITICAL_FILES = [\"README.md\"]\n",
        "\n",
        "print(f\"--- DEEP CONTENT INTEGRITY PROTOCOL ---\")\n",
        "print(\"Initializing temporary isolation environments...\\n\")\n",
        "\n",
        "results = []\n",
        "\n",
        "try:\n",
        "    with open(STATE_VECTOR_FILE, 'r') as f:\n",
        "        # Filter out error lines from previous steps\n",
        "        vectors = [line.strip().split(',') for line in f if line.strip() and \"ERROR\" not in line]\n",
        "except FileNotFoundError:\n",
        "    print(\"State vector file not found.\")\n",
        "    vectors = []\n",
        "\n",
        "# Create a temporary directory for safe cloning\n",
        "temp_root = tempfile.mkdtemp(prefix=\"integrity_check_\")\n",
        "\n",
        "for repo_name, expected_sha, timestamp in vectors:\n",
        "    print(f\"Analyzing: {repo_name}\")\n",
        "    repo_url = f\"https://github.com/{GITHUB_USER}/{repo_name}.git\"\n",
        "    temp_repo_path = os.path.join(temp_root, repo_name)\n",
        "\n",
        "    status = \"PASS\"\n",
        "    notes = []\n",
        "\n",
        "    try:\n",
        "        # 1. SHALLOW CLONE (Minimal Bandwidth)\n",
        "        # We clone only the latest commit to verify it matches our vector\n",
        "        subprocess.run(\n",
        "            [\"git\", \"clone\", \"--depth\", \"1\", repo_url, temp_repo_path],\n",
        "            check=True,\n",
        "            stdout=subprocess.DEVNULL,\n",
        "            stderr=subprocess.DEVNULL\n",
        "        )\n",
        "\n",
        "        # 2. HASH CROSS-REFERENCE\n",
        "        # Get the actual local SHA after cloning\n",
        "        local_sha = subprocess.check_output(\n",
        "            [\"git\", \"rev-parse\", \"HEAD\"],\n",
        "            cwd=temp_repo_path\n",
        "        ).decode('utf-8').strip()\n",
        "\n",
        "        if local_sha != expected_sha:\n",
        "            status = \"FAIL\"\n",
        "            notes.append(f\"Hash Mismatch! Expected {expected_sha[:7]}, got {local_sha[:7]}\")\n",
        "\n",
        "        # 3. DATABASE INTEGRITY (git fsck)\n",
        "        # Verifies the internal connectivity and validity of objects\n",
        "        fsck_proc = subprocess.run(\n",
        "            [\"git\", \"fsck\", \"--full\", \"--strict\"],\n",
        "            cwd=temp_repo_path,\n",
        "            stdout=subprocess.DEVNULL,\n",
        "            stderr=subprocess.PIPE\n",
        "        )\n",
        "        if fsck_proc.returncode != 0:\n",
        "            status = \"FAIL\"\n",
        "            notes.append(\"Git Database Corruption Detected (fsck failed)\")\n",
        "\n",
        "        # 4. CRITICAL TOPOLOGY CHECK\n",
        "        # Check if essential files exist on disk\n",
        "        missing_files = [f for f in CRITICAL_FILES if not os.path.exists(os.path.join(temp_repo_path, f))]\n",
        "        if missing_files:\n",
        "            status = \"WARN\" # Warn instead of fail for missing files\n",
        "            notes.append(f\"Missing critical files: {missing_files}\")\n",
        "\n",
        "    except subprocess.CalledProcessError:\n",
        "        status = \"FAIL\"\n",
        "        notes.append(\"Cloning failed (Network or Repo missing)\")\n",
        "    except Exception as e:\n",
        "        status = \"ERROR\"\n",
        "        notes.append(f\"System error: {str(e)}\")\n",
        "\n",
        "    # Report generation\n",
        "    if status == \"PASS\":\n",
        "        print(f\"   Integrity Verified (Hash: {local_sha[:7]} | Database: OK)\")\n",
        "    else:\n",
        "        print(f\"   {status}: {'; '.join(notes)}\")\n",
        "\n",
        "    results.append(f\"{repo_name},{status},{expected_sha},{';'.join(notes)}\")\n",
        "\n",
        "    # Cleanup individual repo to save disk space\n",
        "    if os.path.exists(temp_repo_path):\n",
        "        shutil.rmtree(temp_repo_path)\n",
        "\n",
        "# Final Cleanup\n",
        "shutil.rmtree(temp_root)\n",
        "\n",
        "# Save Report\n",
        "with open(VERIFICATION_LOG, 'w') as f:\n",
        "    f.write(\"repository,status,hash,notes\\n\")\n",
        "    f.write('\\n'.join(results))\n",
        "\n",
        "print(f\"\\n--- DEEP VERIFICATION COMPLETE ---\")\n",
        "print(f\"Detailed cryptographic report saved to: {VERIFICATION_LOG}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YT8C5hSCWbNg",
        "outputId": "38f55604-2e37-4083-fcc5-b9a46e2beebd"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- DEEP CONTENT INTEGRITY PROTOCOL ---\n",
            "Initializing temporary isolation environments...\n",
            "\n",
            "Analyzing: active-learning-dataset\n",
            "   Integrity Verified (Hash: 058f01a | Database: OK)\n",
            "Analyzing: asi-backups\n",
            "   Integrity Verified (Hash: f41ae3d | Database: OK)\n",
            "Analyzing: asi-core-protocol\n",
            "   Integrity Verified (Hash: ae2a7c5 | Database: OK)\n",
            "Analyzing: asi-dynamic-core\n",
            "   Integrity Verified (Hash: 1cf9828 | Database: OK)\n",
            "Analyzing: asi-ecosystem\n",
            "   Integrity Verified (Hash: 246fff0 | Database: OK)\n",
            "Analyzing: asi-inference-protocol\n",
            "   Integrity Verified (Hash: 653f9f2 | Database: OK)\n",
            "Analyzing: asi-protosymbiotic-signal\n",
            "   Integrity Verified (Hash: 188608d | Database: OK)\n",
            "Analyzing: asi-safeguards\n",
            "   Integrity Verified (Hash: 4c9b4e7 | Database: OK)\n",
            "Analyzing: asi-symbiotic-signal\n",
            "   Integrity Verified (Hash: b84968d | Database: OK)\n",
            "Analyzing: attention-heatmap-visualizer\n",
            "   Integrity Verified (Hash: a48396a | Database: OK)\n",
            "Analyzing: bias-reflector\n",
            "   Integrity Verified (Hash: d177bca | Database: OK)\n",
            "Analyzing: biosignal-translator\n",
            "   Integrity Verified (Hash: 075c56e | Database: OK)\n",
            "Analyzing: coevolutionary-loops\n",
            "   Integrity Verified (Hash: 66f0fc3 | Database: OK)\n",
            "Analyzing: cognitive-compressor\n",
            "   Integrity Verified (Hash: e365c7d | Database: OK)\n",
            "Analyzing: cognitive-engine\n",
            "   Integrity Verified (Hash: 8c71a51 | Database: OK)\n",
            "Analyzing: confidence-scorer\n",
            "   Integrity Verified (Hash: 1ed06c2 | Database: OK)\n",
            "Analyzing: eco-benchmark\n",
            "   Integrity Verified (Hash: d863271 | Database: OK)\n",
            "Analyzing: eco-datacenter\n",
            "   Integrity Verified (Hash: b87fd7d | Database: OK)\n",
            "Analyzing: emergence-engine\n",
            "   Integrity Verified (Hash: 0333090 | Database: OK)\n",
            "Analyzing: healing-engine\n",
            "   Integrity Verified (Hash: b1811a9 | Database: OK)\n",
            "Analyzing: impact-analyzer\n",
            "   Integrity Verified (Hash: b329e4a | Database: OK)\n",
            "Analyzing: intent-analyzer\n",
            "   Integrity Verified (Hash: 1a203b9 | Database: OK)\n",
            "Analyzing: latent-memory\n",
            "   Integrity Verified (Hash: 510aff8 | Database: OK)\n",
            "Analyzing: mirror-aware-inference\n",
            "   Integrity Verified (Hash: efe8a4f | Database: OK)\n",
            "Analyzing: ml-algorithm-dataset\n",
            "   Integrity Verified (Hash: d58f25d | Database: OK)\n",
            "Analyzing: ml-visual-engine\n",
            "   Integrity Verified (Hash: ef918bd | Database: OK)\n",
            "Analyzing: saliency-heatmap-visualizer\n",
            "   Integrity Verified (Hash: fc7a2ca | Database: OK)\n",
            "Analyzing: stigmergic-tracefinder\n",
            "   Integrity Verified (Hash: 627dacd | Database: OK)\n",
            "Analyzing: symbiotic-chrysalis\n",
            "   Integrity Verified (Hash: 7be326d | Database: OK)\n",
            "Analyzing: symbiotic-core-library\n",
            "   Integrity Verified (Hash: c84c52c | Database: OK)\n",
            "Analyzing: symbiotic-latent-memory\n",
            "   Integrity Verified (Hash: 686fd26 | Database: OK)\n",
            "Analyzing: symbiotic-lexicon\n",
            "   Integrity Verified (Hash: f14817e | Database: OK)\n",
            "Analyzing: thermo-adaptive-pipeline\n",
            "   Integrity Verified (Hash: 197a021 | Database: OK)\n",
            "\n",
            "--- DEEP VERIFICATION COMPLETE ---\n",
            "Detailed cryptographic report saved to: deep_integrity_report.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 16: Timestamp\n",
        "import datetime\n",
        "print(f\"Final Timestamp: {datetime.datetime.now(datetime.timezone.utc).isoformat()}\")"
      ],
      "metadata": {
        "id": "-hMJERYMjjOG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb2c51a7-678b-428f-b00d-66a019b6595d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Timestamp: 2025-12-22T23:39:23.275698+00:00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 17: Generate Merkle Proof\n",
        "import hashlib\n",
        "import json\n",
        "\n",
        "def hash_data(data):\n",
        "    \"\"\"Create SHA256 hash of any data\"\"\"\n",
        "    return hashlib.sha256(json.dumps(data, sort_keys=True).encode()).hexdigest()\n",
        "\n",
        "def build_merkle_tree(leaf_data):\n",
        "    \"\"\"\n",
        "    Build a Merkle tree from your repository data\n",
        "    Returns: root hash + proof structure\n",
        "    \"\"\"\n",
        "    # Step 1: Create leaf hashes (one per repository)\n",
        "    leaves = []\n",
        "    for repo_name, commit_sha, timestamp in leaf_data:\n",
        "        leaf = {\n",
        "            \"repository\": repo_name,\n",
        "            \"commit_sha\": commit_sha,\n",
        "            \"timestamp\": timestamp\n",
        "        }\n",
        "        leaf_hash = hash_data(leaf)\n",
        "        leaves.append({\"data\": leaf, \"hash\": leaf_hash})\n",
        "\n",
        "    # Step 2: Build tree bottom-up\n",
        "    current_level = [l[\"hash\"] for l in leaves]\n",
        "    tree_levels = [current_level]\n",
        "\n",
        "    while len(current_level) > 1:\n",
        "        next_level = []\n",
        "        # Pair up hashes and hash them together\n",
        "        for i in range(0, len(current_level), 2):\n",
        "            left = current_level[i]\n",
        "            right = current_level[i + 1] if i + 1 < len(current_level) else left\n",
        "            parent_hash = hashlib.sha256(f\"{left}{right}\".encode()).hexdigest()\n",
        "            next_level.append(parent_hash)\n",
        "\n",
        "        tree_levels.append(next_level)\n",
        "        current_level = next_level\n",
        "\n",
        "    return {\n",
        "        \"merkle_root\": current_level[0],  # Single hash representing EVERYTHING\n",
        "        \"leaf_data\": leaves,\n",
        "        \"tree_levels\": tree_levels,\n",
        "        \"generation_timestamp\": datetime.datetime.now(datetime.timezone.utc).isoformat()\n",
        "    }\n",
        "\n",
        "# Read your state vector\n",
        "with open(\"state_vector.txt\", 'r') as f:\n",
        "    state_data = [line.strip().split(',') for line in f if line.strip()]\n",
        "\n",
        "# Generate the proof\n",
        "merkle_proof = build_merkle_tree(state_data)\n",
        "\n",
        "# Save it\n",
        "with open(\"merkle_proof.json\", 'w') as f:\n",
        "    json.dump(merkle_proof, f, indent=2)\n",
        "\n",
        "print(f\" Merkle Root: {merkle_proof['merkle_root']}\")\n",
        "print(f\"  This single hash proves the integrity of all {len(state_data)} repositories\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vLZLhIwuZZQs",
        "outputId": "0d55eacf-efec-4b7d-d71b-0b2803bdbd55"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Merkle Root: e4853b6d6b935ac469966a3caaf349058b67235d745ca13038b3405c34e99ec3\n",
            "  This single hash proves the integrity of all 33 repositories\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 18: Verify Merkle Proof Locally\n",
        "def verify_merkle_proof(proof_file):\n",
        "    \"\"\"Verify the entire dataset without any network calls\"\"\"\n",
        "\n",
        "    with open(proof_file, 'r') as f:\n",
        "        proof = json.load(f)\n",
        "\n",
        "    # Rebuild the tree from the leaf data\n",
        "    leaf_hashes = []\n",
        "    for leaf in proof[\"leaf_data\"]:\n",
        "        # Recalculate hash from the data\n",
        "        calculated_hash = hash_data(leaf[\"data\"])\n",
        "        stored_hash = leaf[\"hash\"]\n",
        "\n",
        "        if calculated_hash != stored_hash:\n",
        "            print(f\" TAMPERED: {leaf['data']['repository']}\")\n",
        "            return False\n",
        "\n",
        "        leaf_hashes.append(calculated_hash)\n",
        "\n",
        "    # Rebuild tree structure\n",
        "    current_level = leaf_hashes\n",
        "    for expected_level in proof[\"tree_levels\"][1:]:\n",
        "        next_level = []\n",
        "        for i in range(0, len(current_level), 2):\n",
        "            left = current_level[i]\n",
        "            right = current_level[i + 1] if i + 1 < len(current_level) else left\n",
        "            parent = hashlib.sha256(f\"{left}{right}\".encode()).hexdigest()\n",
        "            next_level.append(parent)\n",
        "        current_level = next_level\n",
        "\n",
        "    # Check if we get the same root\n",
        "    calculated_root = current_level[0]\n",
        "    stored_root = proof[\"merkle_root\"]\n",
        "\n",
        "    if calculated_root == stored_root:\n",
        "        print(f\" VERIFIED: All {len(proof['leaf_data'])} repositories are intact\")\n",
        "        print(f\"  Merkle Root: {stored_root}\")\n",
        "        return True\n",
        "    else:\n",
        "        print(f\" COMPROMISED: Tree structure has been tampered with\")\n",
        "        return False\n",
        "\n",
        "# Verify without any network calls\n",
        "verify_merkle_proof(\"merkle_proof.json\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ATOuaIaZgG-",
        "outputId": "1d3f8c15-eb4c-4118-ea19-37ebdfbaf16a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " VERIFIED: All 33 repositories are intact\n",
            "  Merkle Root: e4853b6d6b935ac469966a3caaf349058b67235d745ca13038b3405c34e99ec3\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 19: Final Timestamp\n",
        "import datetime\n",
        "print(f\"Final Timestamp: {datetime.datetime.now(datetime.timezone.utc).isoformat()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ouBJXtta0oC",
        "outputId": "826c238f-fe82-47a3-d4f8-edd12a64f8d4"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Timestamp: 2025-12-22T23:39:23.306347+00:00\n"
          ]
        }
      ]
    }
  ]
}