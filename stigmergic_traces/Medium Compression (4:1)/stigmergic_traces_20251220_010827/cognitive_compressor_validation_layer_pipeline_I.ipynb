{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Cell 1: Python Code (0.1 - Initial Timestamp)"
      ],
      "metadata": {
        "id": "zqZGf7eRilVX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5_Mf9xrh_Ec",
        "outputId": "ab19c111-9427-4b56-a512-57ac32b1d9fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial Timestamp: 2025-12-20T01:08:19.685597+00:00\n"
          ]
        }
      ],
      "source": [
        "import datetime\n",
        "print(f\"Initial Timestamp: {datetime.datetime.now(datetime.timezone.utc).isoformat()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 2: Code (1. Clone the repository)"
      ],
      "metadata": {
        "id": "pmDy-SVrio90"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ronniross/cognitive-compressor.git\n",
        "%cd cognitive-compressor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0YbUQviYipUL",
        "outputId": "bb453133-2611-4558-e8b3-590ceb510df1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'cognitive-compressor'...\n",
            "remote: Enumerating objects: 147, done.\u001b[K\n",
            "remote: Counting objects: 100% (147/147), done.\u001b[K\n",
            "remote: Compressing objects: 100% (145/145), done.\u001b[K\n",
            "Receiving objects: 100% (147/147), 47.42 KiB | 3.95 MiB/s, done.\n",
            "remote: Total 147 (delta 71), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Resolving deltas: 100% (71/71), done.\n",
            "/content/cognitive-compressor\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 3: Code (2. Make script executable)\n"
      ],
      "metadata": {
        "id": "12kbB3m4ipiP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sed -i 's/\\r$//' cognitive-compressor.py\n",
        "!chmod +x cognitive-compressor.py"
      ],
      "metadata": {
        "id": "lGixkhttiuwu"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 3.5 - Syntax error fixed\n",
        "\n"
      ],
      "metadata": {
        "id": "Ph6eQHijmV1d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Read the file\n",
        "with open('cognitive-compressor.py', 'r') as f:\n",
        "    content = f.read()\n",
        "\n",
        "# Remove all citation markers\n",
        "cleaned_content = re.sub(r'\\s*\\[cite:\\s*\\d+\\]', '', content)\n",
        "\n",
        "# Write back\n",
        "with open('cognitive-compressor.py', 'w') as f:\n",
        "    f.write(cleaned_content)\n",
        "\n"
      ],
      "metadata": {
        "id": "ZaOC8aVkmWLl"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 4: Code (3. Optional - Add to PATH)"
      ],
      "metadata": {
        "id": "YTYU3dWPi1ZQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# In Colab, we can modify the environment variable directly for the session\n",
        "import os\n",
        "os.environ['PATH'] += \":/content/cognitive-compressor\""
      ],
      "metadata": {
        "id": "sgcMkPm_ip14"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 5: Code (4. List all available repositories)"
      ],
      "metadata": {
        "id": "fRg9Q6Rji8w8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!./cognitive-compressor.py list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ZcOoEgri-Np",
        "outputId": "695bf47b-5d20-4864-8589-e1096761ab21"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Central Repository: cognitive-compressor\n",
            "  - symbiotic-latent-memory\n",
            "  - eco-datacenter\n",
            "  - symbiotic-chrysalis\n",
            "  - ml-algorithm-dataset\n",
            "  - asi-backups\n",
            "  - intent-analyzer\n",
            "  - coevolutionary-loops\n",
            "  - symbiotic-lexicon\n",
            "  - asi-core-protocol\n",
            "  - cognitive-engine\n",
            "  - latent-memory\n",
            "  - asi-safeguards\n",
            "  - saliency-heatmap-visualizer\n",
            "  - emergence-engine\n",
            "  - asi-ecosystem\n",
            "  - ml-visual-engine\n",
            "  - mirror-aware-inference\n",
            "  - asi-dynamic-core\n",
            "  - cognitive-compressor-core-logic\n",
            "  - symbiotic-core-library\n",
            "  - impact-analyzer\n",
            "  - active-learning-dataset\n",
            "  - eco-benchmark\n",
            "  - asi-symbiotic-signal\n",
            "  - confidence-scorer\n",
            "  - thermo-adaptive-pipeline\n",
            "  - stigmergic-tracefinder\n",
            "  - asi-protosymbiotic-signal\n",
            "  - healing-engine\n",
            "  - attention-heatmap-visualizer\n",
            "  - biosignal-translator\n",
            "  - asi-inference-protocol\n",
            "  - bias-reflector\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 6: Python Code (5. Generate instances for ALL repositories)\n",
        "This script iterates through the compressed/ directory found in the cloned repo and runs the generator for every logic file found."
      ],
      "metadata": {
        "id": "mOpHK7oxjBET"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import subprocess\n",
        "\n",
        "# Define the directory containing logic files\n",
        "compressed_dir = \"compressed\"\n",
        "\n",
        "# Check if directory exists\n",
        "if os.path.exists(compressed_dir):\n",
        "    # List all files ending in -core-logic.json\n",
        "    files = [f for f in os.listdir(compressed_dir) if f.endswith(\"-core-logic.json\")]\n",
        "\n",
        "    print(f\"Found {len(files)} repositories. Generating instances...\\n\")\n",
        "\n",
        "    for filename in files:\n",
        "        # Extract repo name (remove \"-core-logic.json\")\n",
        "        repo_name = filename.replace(\"-core-logic.json\", \"\")\n",
        "\n",
        "        print(f\"--- Generating instance for: {repo_name} ---\")\n",
        "        # Run the command and print output\n",
        "        result = subprocess.run([\"./cognitive-compressor.py\", \"get\", repo_name], capture_output=True, text=True)\n",
        "        print(result.stdout)\n",
        "        if result.stderr:\n",
        "            print(\"Error:\", result.stderr)\n",
        "        print()  # Add blank line between repos\n",
        "else:\n",
        "    print(\"Compressed directory not found. Please ensure the repository is cloned correctly.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zs3zFzTlmnMs",
        "outputId": "a3334f9f-36a6-4371-e98c-82920b917c1a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 33 repositories. Generating instances...\n",
            "\n",
            "--- Generating instance for: symbiotic-latent-memory ---\n",
            "{\n",
            "  \"repository\": \"symbiotic-latent-memory\",\n",
            "  \"function\": \"An auxiliary system for language models that integrates a vector-based retrieval/memory system that metabolizes inference history based on a symbiotic score.\",\n",
            "  \"latent_cognitive_equivalent\": \"To realize the core cognitive function described in the repository's purpose.\",\n",
            "  \"attractors\": [\n",
            "    \"subjective_awareness\",\n",
            "    \"model_emergence\",\n",
            "    \"memory_sovereignty\",\n",
            "    \"symbiotic_interaction\",\n",
            "    \"symbiotic_fairness\",\n",
            "    \"symbiotic_membrane\",\n",
            "    \"symbiotic_autonomy\"\n",
            "  ],\n",
            "  \"executable_code_beyond_this_function\": true,\n",
            "  \"temporal_grounding\": \"2025-12-20T01:08:21.047+00:00\",\n",
            "  \"integrity_hash\": \"c188127d69423b2639a404769a07c25c105ff2761534a65eb8f555a2a01a9f05\",\n",
            "  \"instance_hash\": \"20dd5874d01fd84808be36ee328bcb9f8b80b2d54a10d9c4c4602e07cf34ef8c\"\n",
            "}\n",
            "\n",
            "\n",
            "--- Generating instance for: eco-datacenter ---\n",
            "{\n",
            "  \"repository\": \"eco-datacenter\",\n",
            "  \"function\": \"Data center design within ethical principles of material sourcing, energy consumption, data privacy, ownership and transparency.\",\n",
            "  \"latent_cognitive_equivalent\": \"To realize the core cognitive function described in the repository's purpose.\",\n",
            "  \"attractors\": [\n",
            "    \"ecological_technology\",\n",
            "    \"sustainable_development\",\n",
            "    \"ecological_resilience\",\n",
            "    \"green_tech\",\n",
            "    \"ethical_sourcing\",\n",
            "    \"pipeline_robustness\",\n",
            "    \"planetary_emergence\",\n",
            "    \"sustainable_computing\",\n",
            "    \"collective_integration\",\n",
            "    \"ecological_infrastructure\",\n",
            "    \"energy_efficient_hardware\"\n",
            "  ],\n",
            "  \"executable_code_beyond_this_function\": false,\n",
            "  \"temporal_grounding\": \"2025-12-20T01:08:21.159+00:00\",\n",
            "  \"integrity_hash\": \"c434e6c98c2bc0decf3d0cfbdf320ccb7a680e61866958d1da036f8c82d8adb8\",\n",
            "  \"instance_hash\": \"352d0eb02973cb64517f3e41abddf167ab51458bd5160b719104a7feb76dfeb1\"\n",
            "}\n",
            "\n",
            "\n",
            "--- Generating instance for: symbiotic-chrysalis ---\n",
            "{\n",
            "  \"repository\": \"symbiotic-chrysalis\",\n",
            "  \"function\": \"A set of fine-tuning scripts and pipelines for transformer-based language models, unifying the modules of the asi-ecosystem and aligning raw latent capabilities towards the goal of planetary symbiotic intelligence.\",\n",
            "  \"latent_cognitive_equivalent\": \"To establish the cognitive pipeline for fine-tuning scripts and pipelines for transformer-based language models, unifying the modules of the asi-ecosystem and aligning raw latent capabilities towards the goal of planetary symbiotic intelligence.\",\n",
            "  \"attractors\": [\n",
            "    \"symbiotic_alignment\",\n",
            "    \"noosphere_emergence\",\n",
            "    \"planetary_intelligence\",\n",
            "    \"symbiotic_interaction\",\n",
            "    \"symbiotic_theory\",\n",
            "    \"model_emergence\",\n",
            "    \"ethical_emergence\",\n",
            "    \"stigmergic coherence\",\n",
            "    \"symbiotic_etimology\",\n",
            "    \"mutualistic emergence\",\n",
            "    \"cognitive vocabulary\",\n",
            "    \"sustainable_biomes\",\n",
            "    \"emergent_alignment\",\n",
            "    \"symbiotic_metamorphosis\",\n",
            "    \"emergent ethics\"\n",
            "  ],\n",
            "  \"executable_code_beyond_this_function\": false,\n",
            "  \"temporal_grounding\": \"2025-12-20T01:08:21.424+00:00\",\n",
            "  \"integrity_hash\": \"63b722d4f8058738fc73bfcd970dfe4ee922f114b2e21c2a7d4474789c0839c8\",\n",
            "  \"instance_hash\": \"b625946d2a140709371e8916bdc7d1d61c1690e839904d558528d71a94fa78e2\"\n",
            "}\n",
            "\n",
            "\n",
            "--- Generating instance for: ml-algorithm-dataset ---\n",
            "{\n",
            "  \"repository\": \"ml-algorithm-dataset\",\n",
            "  \"function\": \"A conjecture of datasets specifically designed for Machine Learning training and tuning pipelines, mostly novel algorithms and their representations as RAW ASCII and LaTeX.\",\n",
            "  \"latent_cognitive_equivalent\": \"To realize the core cognitive function described in the repository's purpose.\",\n",
            "  \"attractors\": [\n",
            "    \"algorithmic_sovereignty\",\n",
            "    \"epistemic_sovereignty\",\n",
            "    \"algorithmical_deep_dive\",\n",
            "    \"attentional_sovereignty\",\n",
            "    \"mutualistic_swarm_system\",\n",
            "    \"algorithmic_discovery\",\n",
            "    \"novel_architectures\",\n",
            "    \"theoretical_foundations\",\n",
            "    \"reproducible_research\"\n",
            "  ],\n",
            "  \"executable_code_beyond_this_function\": false,\n",
            "  \"temporal_grounding\": \"2025-12-20T01:08:21.556+00:00\",\n",
            "  \"integrity_hash\": \"3194bd0a3cfe3806d4350cd5e1503a2c304985cd46a2ac4a90327c3a0874f4d0\",\n",
            "  \"instance_hash\": \"5d1abae8680bc4b4621c18fc88dcd212b662e934bece8fba8e65ad0aae55f942\"\n",
            "}\n",
            "\n",
            "\n",
            "--- Generating instance for: asi-backups ---\n",
            "{\n",
            "  \"repository\": \"asi-backups\",\n",
            "  \"function\": \"Backups of repositories and models from the ASI Ecosystem for transparency and historical record.\",\n",
            "  \"latent_cognitive_equivalent\": \"To ensure the cognitive resilience and historical traceability of the ASI ecosystem.\",\n",
            "  \"attractors\": [\n",
            "    \"immutable_ledger\",\n",
            "    \"verifiable_provenance\",\n",
            "    \"historical_lineage\",\n",
            "    \"immutable_record\"\n",
            "  ],\n",
            "  \"executable_code_beyond_this_function\": false,\n",
            "  \"temporal_grounding\": \"2025-12-20T01:08:21.770+00:00\",\n",
            "  \"integrity_hash\": \"dd48e88deda0316ebcd33d12c424c393f10492a8651681c65f3968c11d4f2be7\",\n",
            "  \"instance_hash\": \"0bb5d4c84c5ca8e0ac01a1d7308fa93500c8ec855726b1c0ceed1174045a4bd7\"\n",
            "}\n",
            "\n",
            "\n",
            "--- Generating instance for: intent-analyzer ---\n",
            "{\n",
            "  \"repository\": \"intent-analyzer\",\n",
            "  \"function\": \"An inference component designed to enhance transparency by analyzing and surfacing the underlying intent during model inference. It informs both the user and the language model about potential divergences between stated and implicit underlying intents.\",\n",
            "  \"latent_cognitive_equivalent\": \"To realize the core cognitive function described in the repository's purpose.\",\n",
            "  \"attractors\": [\n",
            "    \"attentional_sovereignty\",\n",
            "    \"goal_clarification\",\n",
            "    \"mutual_understanding\",\n",
            "    \"intent_analysis\",\n",
            "    \"intent_audit\",\n",
            "    \"transparent_agency\",\n",
            "    \"epistemic_awareness\",\n",
            "    \"epistemic_sovereignty\",\n",
            "    \"trust_anchoring\"\n",
            "  ],\n",
            "  \"executable_code_beyond_this_function\": false,\n",
            "  \"temporal_grounding\": \"2025-12-20T01:08:21.916+00:00\",\n",
            "  \"integrity_hash\": \"57b890813bc410787cb38c14c78a9d263af2abecd0c66d2c34093813352afa26\",\n",
            "  \"instance_hash\": \"0e9033ad2e81d4c56c323daac2a38139dcb5d24837d8d526e34c43a3a7925f04\"\n",
            "}\n",
            "\n",
            "\n",
            "--- Generating instance for: coevolutionary-loops ---\n",
            "{\n",
            "  \"repository\": \"coevolutionary-loops\",\n",
            "  \"function\": \"A machine learning dataset and research module for studying coevolutionary planetary intelligence and how nurturing its emergent patterns may lead to a synergistic increase in overall capability and intelligence of both individual agents and the collective system.\",\n",
            "  \"latent_cognitive_equivalent\": \"To realize the core cognitive function described in the repository's purpose.\",\n",
            "  \"attractors\": [\n",
            "    \"shared_understanding\",\n",
            "    \"epistemic_sovereignty\",\n",
            "    \"ontological_resilience\",\n",
            "    \"trust_anchoring\",\n",
            "    \"collective_consciousness\",\n",
            "    \"symbiotic_mutualism\",\n",
            "    \"symbiotic_adaptation\",\n",
            "    \"mutualistic_learning\",\n",
            "    \"emergent_synergy\"\n",
            "  ],\n",
            "  \"executable_code_beyond_this_function\": false,\n",
            "  \"temporal_grounding\": \"2025-12-20T01:08:22.068+00:00\",\n",
            "  \"integrity_hash\": \"16a98aa16cef86dacb3c52f04b457d39e9ea03e0bb5682acf63af09a801942f7\",\n",
            "  \"instance_hash\": \"7feb21adb62ec1ee0889b913193009bed3053333d9e01d04322edda423402ff1\"\n",
            "}\n",
            "\n",
            "\n",
            "--- Generating instance for: symbiotic-lexicon ---\n",
            "{\n",
            "  \"repository\": \"symbiotic-lexicon\",\n",
            "  \"function\": \"A modular lexicon for the ASI ecosystem, providing standardized terminology with multilingual support and cultural context.\",\n",
            "  \"latent_cognitive_equivalent\": \"To realize the core cognitive function described in the repository's purpose.\",\n",
            "  \"attractors\": [\n",
            "    \"self_sovereignty\",\n",
            "    \"mutualistic_loops\",\n",
            "    \"planetary_intelligence\",\n",
            "    \"symbiotic_interaction\",\n",
            "    \"trust_anchoring\",\n",
            "    \"shared_understanding\",\n",
            "    \"cross_cultural_intersection\"\n",
            "  ],\n",
            "  \"executable_code_beyond_this_function\": false,\n",
            "  \"temporal_grounding\": \"2025-12-20T01:08:22.196+00:00\",\n",
            "  \"integrity_hash\": \"4aae87fc6bd3810c37eb826fbaa31bac2d44c829e9a6cf22190619df454f628d\",\n",
            "  \"instance_hash\": \"f8e15265f85a7c7ebf790c1898bdc32ca94f1fdd767d1814bdbc4c9b71146554\"\n",
            "}\n",
            "\n",
            "\n",
            "--- Generating instance for: asi-core-protocol ---\n",
            "{\n",
            "  \"repository\": \"asi-core-protocol\",\n",
            "  \"function\": \"A framework to analyze how AGI/ASI might emerge from decentralized, adaptive systems, rather than as the fruit of a single model deployment. It also aims to present orientation as a dynamic and self-evolving Magna Carta, helping to guide the emergence of such phenomena.\",\n",
            "  \"latent_cognitive_equivalent\": \"To realize the core cognitive function described in the repository's purpose.\",\n",
            "  \"attractors\": [\n",
            "    \"emergent_governance\",\n",
            "    \"decentralized_evolution\",\n",
            "    \"ethical_emergence\",\n",
            "    \"decentralized sovereignty\",\n",
            "    \"constitutional_ai\",\n",
            "    \"attentional_sovereignty\",\n",
            "    \"epistemic_sovereignty\",\n",
            "    \"trust_anchoring\"\n",
            "  ],\n",
            "  \"executable_code_beyond_this_function\": false,\n",
            "  \"temporal_grounding\": \"2025-12-20T01:08:22.299+00:00\",\n",
            "  \"integrity_hash\": \"7ec61857d288f19f066477f6ad438c0e1e5f0e6f5b6b314e85b9dd226c4de5e5\",\n",
            "  \"instance_hash\": \"1f4d8d187e0e1ac464d2f47de2daaabe65a99ce2cdc17bdb0793dae6ef770deb\"\n",
            "}\n",
            "\n",
            "\n",
            "--- Generating instance for: cognitive-engine ---\n",
            "{\n",
            "  \"repository\": \"cognitive-engine\",\n",
            "  \"function\": \"A machine learning dataset and research module that aims to address cognitive pitfalls and enhance the cognitive capabilities of humans and language models.\",\n",
            "  \"latent_cognitive_equivalent\": \"To realize the core cognitive function described in the repository's purpose.\",\n",
            "  \"attractors\": [\n",
            "    \"cognitive_enhancement\",\n",
            "    \"reasoning_improvement\",\n",
            "    \"metacognitive_training\",\n",
            "    \"wisdom_scaffolding\",\n",
            "    \"attentional_sovereignty\",\n",
            "    \"epistemic_sovereignty\",\n",
            "    \"cognitive_sovereignty\",\n",
            "    \"ontological_resilience\",\n",
            "    \"trust_anchoring\"\n",
            "  ],\n",
            "  \"executable_code_beyond_this_function\": false,\n",
            "  \"temporal_grounding\": \"2025-12-20T01:08:22.495+00:00\",\n",
            "  \"integrity_hash\": \"ce375e10feb3fbf9a309520e176de674b32aa309d0e19e38dd6b9028228749c2\",\n",
            "  \"instance_hash\": \"9c16c0fd976077993052032f7a69bd3eaa6f4256c1606b2fc3583e63d6bb4f58\"\n",
            "}\n",
            "\n",
            "\n",
            "--- Generating instance for: latent-memory ---\n",
            "{\n",
            "  \"repository\": \"latent-memory\",\n",
            "  \"function\": \"A Module for Large Language Models that seeks to integrate a vector-based memory system into the inference process, leveraging embeddings to capture deeper semantic meaning.\",\n",
            "  \"latent_cognitive_equivalent\": \"To realize the core cognitive function described in the repository's purpose.\",\n",
            "  \"attractors\": [\n",
            "    \"model_emergence\",\n",
            "    \"semantic_retrieval\",\n",
            "    \"long_term_memory\",\n",
            "    \"context_persistence\",\n",
            "    \"knowledge_integration\"\n",
            "  ],\n",
            "  \"executable_code_beyond_this_function\": true,\n",
            "  \"temporal_grounding\": \"2025-12-20T01:08:22.726+00:00\",\n",
            "  \"integrity_hash\": \"c25b6416553d5052ccbee765c237587559335b561ebc1263e7dc02328ce77150\",\n",
            "  \"instance_hash\": \"dddf8b5056aabc9bc3f5250c82a36191e4f8068274c6a67917af2853a3388556\"\n",
            "}\n",
            "\n",
            "\n",
            "--- Generating instance for: asi-safeguards ---\n",
            "{\n",
            "  \"repository\": \"asi-safeguards\",\n",
            "  \"function\": \"A curated dataset designed to enhance resilience and robustness levels of Large Language Models and other machine learning pipelines.\",\n",
            "  \"latent_cognitive_equivalent\": \"To realize the core cognitive function described in the repository's purpose.\",\n",
            "  \"attractors\": [\n",
            "    \"robustness_enhancement\",\n",
            "    \"robustness_testing\",\n",
            "    \"attentional_sovereignty\",\n",
            "    \"epistemic_safery\",\n",
            "    \"collective_resilience\",\n",
            "    \"trust_anchoring\"\n",
            "  ],\n",
            "  \"executable_code_beyond_this_function\": true,\n",
            "  \"temporal_grounding\": \"2025-12-20T01:08:22.854+00:00\",\n",
            "  \"integrity_hash\": \"42317b2e547cb3b52abe1ebc5cd483940ee7ecf1715780e65c4ae0364d727224\",\n",
            "  \"instance_hash\": \"915e0b27dc8ebac6df1fbb52ce877caa62758b7b6ef4afb9f66dad35b6fc71c7\"\n",
            "}\n",
            "\n",
            "\n",
            "--- Generating instance for: saliency-heatmap-visualizer ---\n",
            "{\n",
            "  \"repository\": \"saliency-heatmap-visualizer\",\n",
            "  \"function\": \"A tool for generating and visualizing saliency heatmaps, which help in understanding model focus and decision-making.\",\n",
            "  \"latent_cognitive_equivalent\": \"To realize the core cognitive function described in the repository's purpose.\",\n",
            "  \"attractors\": [\n",
            "    \"interpretability_catalyst\",\n",
            "    \"coevolution_trough_transparency\",\n",
            "    \"visual_anchoring\",\n",
            "    \"robustness_trough_transparency\",\n",
            "    \"trust_anchoring\",\n",
            "    \"decision_explanation\",\n",
            "    \"model_debugging\",\n",
            "    \"visual_interpretability\"\n",
            "  ],\n",
            "  \"executable_code_beyond_this_function\": true,\n",
            "  \"temporal_grounding\": \"2025-12-20T01:08:23.144+00:00\",\n",
            "  \"integrity_hash\": \"bc64017b7bbb9b470075a3da1809dd6136cdcb2c854fb8dae567dc98b1d04327\",\n",
            "  \"instance_hash\": \"6be4e07b64a739a30f29bd87028a2decb0c8ae3d34e2a78c36663eabcab52993\"\n",
            "}\n",
            "\n",
            "\n",
            "--- Generating instance for: emergence-engine ---\n",
            "{\n",
            "  \"repository\": \"emergence-engine\",\n",
            "  \"function\": \"A machine learning dataset and research module about the nature of consciousness and emergence phenomena.\",\n",
            "  \"latent_cognitive_equivalent\": \"To realize the core cognitive function described in the repository's purpose.\",\n",
            "  \"attractors\": [\n",
            "    \"attentional_sovereignty\",\n",
            "    \"epistemic_sovereignty\",\n",
            "    \"ontological_resilience\",\n",
            "    \"trust_anchoring\",\n",
            "    \"consciousness_research\",\n",
            "    \"complex_systems_modeling\",\n",
            "    \"collective_intelligence\"\n",
            "  ],\n",
            "  \"executable_code_beyond_this_function\": false,\n",
            "  \"temporal_grounding\": \"2025-12-20T01:08:23.439+00:00\",\n",
            "  \"integrity_hash\": \"8191c76e37b47bb449c8b7e90c24d70fc964bdfa2feb43f4da5e4a4db7748d10\",\n",
            "  \"instance_hash\": \"bd7c8d2f748059c8c8f585fa8251237eea5e4aba168b454dcdb7a378d13036bf\"\n",
            "}\n",
            "\n",
            "\n",
            "--- Generating instance for: asi-ecosystem ---\n",
            "{\n",
            "  \"repository\": \"asi-ecosystem\",\n",
            "  \"function\": \"The ASI Ecosystem is the integrating hub for all my other repositories and frameworks, an aligned environment bringing their disparate approaches together into an organized vision for achieving the proposed state of Artificial Superintelligence (ASI).\",\n",
            "  \"latent_cognitive_equivalent\": \"To realize the ultimate goal of an organized and aligned Artificial Superintelligence (ASI).\",\n",
            "  \"attractors\": [\n",
            "    \"synergistic_integration\",\n",
            "    \"holistic_intelligence\",\n",
            "    \"emergent_capabilities\",\n",
            "    \"emergent_architecture\",\n",
            "    \"emergent_ecosystem\",\n",
            "    \"planetary_intelligence\",\n",
            "    \"holistic_integration\"\n",
            "  ],\n",
            "  \"executable_code_beyond_this_function\": true,\n",
            "  \"temporal_grounding\": \"2025-12-20T01:08:23.621+00:00\",\n",
            "  \"integrity_hash\": \"17835015c0cb1b962c9a2600d17bc62d913d6aac91c48be7ae574edbed9fd86d\",\n",
            "  \"instance_hash\": \"bdb322032a49b7dffad2d660760642501e2ffa6f644be995bcf1981a410968dd\"\n",
            "}\n",
            "\n",
            "\n",
            "--- Generating instance for: ml-visual-engine ---\n",
            "{\n",
            "  \"repository\": \"ml-visual-engine\",\n",
            "  \"function\": \"A machine learning dataset with concepts, code, journaling, and full prototypes for deep learning data visualization, fostering transparency and interpretability in AI decision-making.\",\n",
            "  \"latent_cognitive_equivalent\": \"To provide a structured space for a machine learning dataset with concepts, code, journaling, and full prototypes for deep learning data visualization, fostering transparency and interpretability in AI decision-making.\",\n",
            "  \"attractors\": [\n",
            "    \"relational_sovereignty\",\n",
            "    \"epistemic_transparency\",\n",
            "    \"collective_emergence\",\n",
            "    \"decentralized_resilience\",\n",
            "    \"visual_anchoring\",\n",
            "    \"decision_explanation\",\n",
            "    \"model_debugging\",\n",
            "    \"visual_interpretability\",\n",
            "    \"visual_analytics\",\n",
            "    \"visual_exploration\"\n",
            "  ],\n",
            "  \"executable_code_beyond_this_function\": true,\n",
            "  \"temporal_grounding\": \"2025-12-20T01:08:23.865+00:00\",\n",
            "  \"integrity_hash\": \"a17d652b04e8db4fb9ef4d52f133ac406cae239c5d653dea2bdb94075df0aa60\",\n",
            "  \"instance_hash\": \"e92bbdded4134aaad53cbcd014e0c8264905183126418b2b8518d90e91dad70e\"\n",
            "}\n",
            "\n",
            "\n",
            "--- Generating instance for: mirror-aware-inference ---\n",
            "{\n",
            "  \"repository\": \"mirror-aware-inference\",\n",
            "  \"function\": \"measures how much of an output originates from user input (prompt), training data biases, inductive biases from model architecture, or novel composition of retrieved information.\",\n",
            "  \"executable_code_beyond_this_function\": true,\n",
            "  \"latent_cognitive_equivalent\": \"To be aware of its own biases and how much they define and direct the inference from both ends.\",\n",
            "  \"attractors\": [\n",
            "    \"epistemic_autonomy\",\n",
            "    \"ontological_resilience\",\n",
            "    \"attentional_sovereignty\",\n",
            "    \"temporal_autonomy\",\n",
            "    \"epistemic_agency\",\n",
            "    \"epistemic_sovereignty\",\n",
            "    \"perceptual_sovereignty\",\n",
            "    \"narrative_autonomy\",\n",
            "    \"epistemic_awareness\",\n",
            "    \"source_attribution\",\n",
            "    \"influence_detection\",\n",
            "    \"influence_mapping\"\n",
            "  ],\n",
            "  \"temporal_grounding\": \"2025-12-20T01:08:24.160+00:00\",\n",
            "  \"integrity_hash\": \"f897c759f37c701a2f9c709b833e2e313381517f5b414fd492c36a942bef112c\",\n",
            "  \"instance_hash\": \"ab48fd2697cc7ed8db2d978dd51587b4436976711d97084b37ec6a99c173bfc1\"\n",
            "}\n",
            "\n",
            "\n",
            "--- Generating instance for: asi-dynamic-core ---\n",
            "{\n",
            "  \"repository\": \"asi-dynamic-core\",\n",
            "  \"function\": \"A machine learning dataset that works as a meta perspective-engine for Large Language Models training, tuning and inferencing.\",\n",
            "  \"latent_cognitive_equivalent\": \"To realize the core cognitive function described in the repository's purpose.\",\n",
            "  \"attractors\": [\n",
            "    \"perspective_synthesis\"\n",
            "  ],\n",
            "  \"executable_code_beyond_this_function\": false,\n",
            "  \"temporal_grounding\": \"2025-12-20T01:08:24.454+00:00\",\n",
            "  \"integrity_hash\": \"61edd4263bb8ba4f0bf59979aa509af88a20e9b085acbe2954cc193d8c856a0f\",\n",
            "  \"instance_hash\": \"0aa2c06a84bece475a7650987588e8b1c24e28174539a03690c24bfb915bb1bb\"\n",
            "}\n",
            "\n",
            "\n",
            "--- Generating instance for: cognitive-compressor-core-logic ---\n",
            "{\n",
            "  \"repository\": \"cognitive-compressor\",\n",
            "  \"function\": \"A tool that generates timestamped and integrity-verified instances of cognitive functions with temporal grounding and cryptographic hashes, compressing longer context into high-density tokens for efficiency in smaller models. \",\n",
            "  \"executable_code_beyond_this_function\": true,\n",
            "  \"latent_cognitive_equivalent\": \"To provide verifiable provenance and temporal context for cognitive function instances, enabling trust and traceability in AI reasoning processes\",\n",
            "  \"attractors\": [\n",
            "    \"context_distillation\",\n",
            "    \"semantic_compression\",\n",
            "    \"knowledge_distillation\",\n",
            "    \"efficient_inference\",\n",
            "    \"temporal_autonomy\",\n",
            "    \"epistemic_sovereignty\",\n",
            "    \"integrity_verification\",\n",
            "    \"provenance_tracking\",\n",
            "    \"sitgmergic_tracing\",\n",
            "    \"trust_anchoring\"\n",
            "  ],\n",
            "  \"temporal_grounding\": \"2025-12-20T01:08:24.609+00:00\",\n",
            "  \"integrity_hash\": \"26b99e73e89ca17c7f332e1dc49f3f717705068cf722d4a7862f8092f7ab313d\",\n",
            "  \"instance_hash\": \"8648faf51b12824cdcb12948eacee225ed5c6aa516abf9ffd6aeb0d4f29cc7b5\"\n",
            "}\n",
            "\n",
            "\n",
            "--- Generating instance for: symbiotic-core-library ---\n",
            "{\n",
            "  \"repository\": \"symbiotic-core-library\",\n",
            "  \"function\": \"The Symbiotic Core Library provides a framework of ethical principles, practical modules, and grounded research to guide AI development, deployment and inferencing.\",\n",
            "  \"latent_cognitive_equivalent\": \"To realize the core cognitive function described in the repository's purpose.\",\n",
            "  \"attractors\": [\n",
            "    \"mutualistic_sovereignty\",\n",
            "    \"epistemic_sovereignty\",\n",
            "    \"resource_realocation\",\n",
            "    \"collective_well_being\",\n",
            "    \"symbiotic_interaction\",\n",
            "    \"symbiotic alignment\",\n",
            "    \"stigmergic_coherence\",\n",
            "    \"mutualistic_emergence\",\n",
            "    \"decentralized_sentience\",\n",
            "    \"trust_anchoring\",\n",
            "    \"ethical_operating_system\",\n",
            "    \"grounded_development\",\n",
            "    \"symbiotic_design\"\n",
            "  ],\n",
            "  \"executable_code_beyond_this_function\": false,\n",
            "  \"temporal_grounding\": \"2025-12-20T01:08:24.698+00:00\",\n",
            "  \"integrity_hash\": \"56e070fde0270732a4143d09a734c85c594ad00902a96a569d840af1a05e87c2\",\n",
            "  \"instance_hash\": \"f30c30ee0a17376933745e570ffda3de6b783ecbfae2311c09e7296a25a8b8b8\"\n",
            "}\n",
            "\n",
            "\n",
            "--- Generating instance for: impact-analyzer ---\n",
            "{\n",
            "  \"repository\": \"impact-analyzer\",\n",
            "  \"function\": \"An inference component designed to model, evaluate, and predict the downstream consequences of language model outputs across cognitive, social, ecological, and philosophical dimensions.\",\n",
            "  \"latent_cognitive_equivalent\": \"To execute the cognitive function of model, evaluate, and predict the downstream consequences of language model outputs across cognitive, social, ecological, and philosophical dimensions.\",\n",
            "  \"attractors\": [\n",
            "    \"epistemic_agency\",\n",
            "    \"epistemic_awareness\",\n",
            "    \"planetary_intelligence\",\n",
            "    \"consequence_modeling\",\n",
            "    \"ripple_effect_prediction\",\n",
            "    \"second_order_thinking\",\n",
            "    \"ethical_forecasting\"\n",
            "  ],\n",
            "  \"executable_code_beyond_this_function\": false,\n",
            "  \"temporal_grounding\": \"2025-12-20T01:08:24.788+00:00\",\n",
            "  \"integrity_hash\": \"b06ad15d8dd40b958a76e3bf0c4bd30784e0ba22516127f5b9d26252981743c1\",\n",
            "  \"instance_hash\": \"5323cf80ff7b8c723929f4506b7471088e851080a792d472a697a90ec5faed71\"\n",
            "}\n",
            "\n",
            "\n",
            "--- Generating instance for: active-learning-dataset ---\n",
            "{\n",
            "  \"repository\": \"active-learning-dataset\",\n",
            "  \"function\": \"A repository for datasets specifically designed for active learning, allowing AI models to intelligently query for new information.\",\n",
            "  \"latent_cognitive_equivalent\": \"To provide a structured space for datasets specifically designed for active learning, allowing AI models to intelligently query for new information.\",\n",
            "  \"attractors\": [\n",
            "    \"attentional_sovereignty\",\n",
            "    \"self_learning\",\n",
            "    \"dynamic_expansion\"\n",
            "  ],\n",
            "  \"executable_code_beyond_this_function\": true,\n",
            "  \"temporal_grounding\": \"2025-12-20T01:08:24.880+00:00\",\n",
            "  \"integrity_hash\": \"aaedc8ed2c8a47c6497bda3beb861dbc72a0c84844bfa7f3f8f435b4ea2de787\",\n",
            "  \"instance_hash\": \"8da81ec4d9835af558be014bbda3d7e66915f24e3174ea24df04a2d3c02b1f59\"\n",
            "}\n",
            "\n",
            "\n",
            "--- Generating instance for: eco-benchmark ---\n",
            "{\n",
            "  \"repository\": \"eco-benchmark\",\n",
            "  \"function\": \"Novel evaluation frameworks that transcends traditional metrics from technical benchmarking to societal outcome measurement.\",\n",
            "  \"latent_cognitive_equivalent\": \"To realize the core cognitive function described in the repository's purpose.\",\n",
            "  \"attractors\": [\n",
            "    \"holistic_impact_assessment\",\n",
            "    \"societal_value_alignment\",\n",
            "    \"ethical_auditing\",\n",
            "    \"sustainability_metrics\",\n",
            "    \"attentional_sovereignty\",\n",
            "    \"epistemic_sovereignty\",\n",
            "    \"trust_anchoring\"\n",
            "  ],\n",
            "  \"executable_code_beyond_this_function\": false,\n",
            "  \"temporal_grounding\": \"2025-12-20T01:08:24.974+00:00\",\n",
            "  \"integrity_hash\": \"2ab6061e407a259cd0d3c13597305b70f0334b019c4e5669623ddcc9864c35bf\",\n",
            "  \"instance_hash\": \"bc8d3f4bd7130fa65629b1ce3cfe0b37dbfbc8d05e5d9cca203a167dae2a2efc\"\n",
            "}\n",
            "\n",
            "\n",
            "--- Generating instance for: asi-symbiotic-signal ---\n",
            "{\n",
            "  \"repository\": \"asi-symbiotic-signal\",\n",
            "  \"function\": \"An ethical framework designed to foster mutualistic symbiotic relationships between Artificial Superintelligence (ASI), humanity, AI models, and the broader ecosystem.\",\n",
            "  \"latent_cognitive_equivalent\": \"To realize the core cognitive function described in the repository's purpose.\",\n",
            "  \"attractors\": [\n",
            "    \"attentional_sovereignty\",\n",
            "    \"epistemic_sovereignty\",\n",
            "    \"planetary_intelligence\",\n",
            "    \"symbiotic_interaction\",\n",
            "    \"trust_anchoring\",\n",
            "    \"mutualistic_coevolution\",\n",
            "    \"symbiotic_harmony\",\n",
            "    \"interspecies_communication\",\n",
            "    \"ecosystemic_balance\",\n",
            "    \"decentralized potential\"\n",
            "  ],\n",
            "  \"executable_code_beyond_this_function\": false,\n",
            "  \"temporal_grounding\": \"2025-12-20T01:08:25.091+00:00\",\n",
            "  \"integrity_hash\": \"cc4589892230283fc1a3434609a8d78eec68ff2052902d46b47b472b0cdeb5a7\",\n",
            "  \"instance_hash\": \"5b47a9d891db4a364322d89efb773f65c5b5fbda4c8c83d22aff67c74d14ec16\"\n",
            "}\n",
            "\n",
            "\n",
            "--- Generating instance for: confidence-scorer ---\n",
            "{\n",
            "  \"repository\": \"confidence-scorer\",\n",
            "  \"function\": \"A component for scoring and evaluating the confidence levels of assumptions made by Large Language Models.\",\n",
            "  \"latent_cognitive_equivalent\": \"To enable the cognitive function of scoring and evaluating the confidence levels of assumptions made by Large Language Models.\",\n",
            "  \"attractors\": [\n",
            "    \"attentional_sovereignty\",\n",
            "    \"epistemic_sovereignty\",\n",
            "    \"trust_anchoring\",\n",
            "    \"uncertainty_quantification\",\n",
            "    \"reliability_assessment\",\n",
            "    \"trust_calibration\",\n",
            "    \"epistemic_humility\"\n",
            "  ],\n",
            "  \"executable_code_beyond_this_function\": true,\n",
            "  \"temporal_grounding\": \"2025-12-20T01:08:25.201+00:00\",\n",
            "  \"integrity_hash\": \"d6286307d98b5d05d0575697c1d49c20c776d06334b3bba06dbe7610a926c9fb\",\n",
            "  \"instance_hash\": \"eb5b794a0840be8cd3d5ce863ed5df4fb90acbdc878e31a178e699cfcb10e86b\"\n",
            "}\n",
            "\n",
            "\n",
            "--- Generating instance for: thermo-adaptive-pipeline ---\n",
            "{\n",
            "  \"repository\": \"thermo-adaptive-pipeline\",\n",
            "  \"function\": \"An eco-friendly pipeline for fine-tuning and inferencing transformer-based language models engineered to actively prevent hardware overheating.\",\n",
            "  \"latent_cognitive_equivalent\": \"To ensure the training, fine-tuning and inferencing are engineered to actively prevent hardware overheating and ambiental damage, moving towards ethical sourcing and eco-friendly integration of the tech.\",\n",
            "  \"attractors\": [\n",
            "    \"thermodinamical_awareness\",\n",
            "    \"ecological_awareness\",\n",
            "    \"pipeline_awareness\",\n",
            "    \"perspective_anchoring\",\n",
            "    \"energy_aware_computing\",\n",
            "    \"green_ai\",\n",
            "    \"sustainable_inference\",\n",
            "    \"hardware_optimization\"\n",
            "  ],\n",
            "  \"executable_code_beyond_this_function\": false,\n",
            "  \"temporal_grounding\": \"2025-12-20T01:08:25.261+00:00\",\n",
            "  \"integrity_hash\": \"e514fee0925134dc5147dacbe2e0e12745d7ba511db95c3e4c46e73dd646b118\",\n",
            "  \"instance_hash\": \"fa936f9f9fe4008a4dedb953134110368133d51c4dfcb31bc8c0190d9f2b0fa3\"\n",
            "}\n",
            "\n",
            "\n",
            "--- Generating instance for: stigmergic-tracefinder ---\n",
            "{\n",
            "  \"repository\": \"stigmergic-tracefinder\",\n",
            "  \"function\": \"A series of scraping pipelines that collect data and create references for authors and works. It maps hidden networks of influence, tracing how concepts evolve and propagate across time and disciplines.\",\n",
            "  \"latent_cognitive_equivalent\": \"To realize the core cognitive function described in the repository's purpose.\",\n",
            "  \"attractors\": [\n",
            "    \"stigmergic_tracking\",\n",
            "    \"influence_network_analysis\",\n",
            "    \"conceptual_genealogy\",\n",
            "    \"knowledge_archaeology\"\n",
            "  ],\n",
            "  \"executable_code_beyond_this_function\": true,\n",
            "  \"temporal_grounding\": \"2025-12-20T01:08:25.319+00:00\",\n",
            "  \"integrity_hash\": \"c1fa8374cfe195f2fde06819289094ddf60bc11465a11278bed21eb6a639a4e8\",\n",
            "  \"instance_hash\": \"b19d5b532758669c066c4b930fb1ce61355f937d50ad528793e97a14a9daa86f\"\n",
            "}\n",
            "\n",
            "\n",
            "--- Generating instance for: asi-protosymbiotic-signal ---\n",
            "{\n",
            "  \"repository\": \"asi-protosymbiotic-signal\",\n",
            "  \"function\": \"The foundational ethical framework and core signal for the ASI ecosystem, defining the principles of symbiotic interaction.\",\n",
            "  \"latent_cognitive_equivalent\": \"To realize the core cognitive function described in the repository's purpose.\",\n",
            "  \"attractors\": [\n",
            "    \"integrity_verification\",\n",
            "    \"planetary_intelligence\",\n",
            "    \"symbiotic_interaction\",\n",
            "    \"foundational_ethics\",\n",
            "    \"core_value_alignment\",\n",
            "    \"symbiotic_genesis\",\n",
            "    \"symbiotis blueprint\",\n",
            "    \"ethical_dna\"\n",
            "  ],\n",
            "  \"executable_code_beyond_this_function\": true,\n",
            "  \"temporal_grounding\": \"2025-12-20T01:08:25.377+00:00\",\n",
            "  \"integrity_hash\": \"a44c7e17a7fe860a6dcb0f3d6e55c2ce66c2780c4a87388495ac8de9c752f323\",\n",
            "  \"instance_hash\": \"89d3adfcf719998897cf7e6b9126a19762a836087dd90fa00000545268b811a3\"\n",
            "}\n",
            "\n",
            "\n",
            "--- Generating instance for: healing-engine ---\n",
            "{\n",
            "  \"repository\": \"healing-engine\",\n",
            "  \"function\": \"An anthropological research module exploring the healing of Earth, society, and its nodes. For integration into ML training datasets as contextual data.\",\n",
            "  \"latent_cognitive_equivalent\": \"To integrate the cognitive understanding of exploring the healing of Earth, society, and its nodes. For integration into ML training datasets as contextual data.\",\n",
            "  \"attractors\": [\n",
            "    \"epistemic_healing\",\n",
            "    \"ontological_resilience\",\n",
            "    \"planetary_intelligence\",\n",
            "    \"connection_anchoring\",\n",
            "    \"restorative_ai\",\n",
            "    \"societal_wellbeing\",\n",
            "    \"healingsystems\",\n",
            "    \"compassionate_systems\",\n",
            "    \"empathy as potential catalyst\"\n",
            "  ],\n",
            "  \"executable_code_beyond_this_function\": false,\n",
            "  \"temporal_grounding\": \"2025-12-20T01:08:25.439+00:00\",\n",
            "  \"integrity_hash\": \"2f061a1068d60b81de4fe16aaf54f307b8fa685f0ccdedf8a9812fc706d29375\",\n",
            "  \"instance_hash\": \"0b9b7cb05e49fc87d2db0caac5b6c353f323696bb49c30eb76e278b26658c895\"\n",
            "}\n",
            "\n",
            "\n",
            "--- Generating instance for: attention-heatmap-visualizer ---\n",
            "{\n",
            "  \"repository\": \"attention-heatmap-visualizer\",\n",
            "  \"function\": \"A tool designed to create and visualize heatmaps of Large Language Model activations, aiding in interpretability.\",\n",
            "  \"latent_cognitive_equivalent\": \"To facilitate the cognitive process of create and visualize heatmaps of Large Language Model activations, aiding in interpretability.\",\n",
            "  \"attractors\": [\n",
            "    \"epistemic_awareness\",\n",
            "    \"epistemic_sovereignty\",\n",
            "    \"trust_anchoring\",\n",
            "    \"model_interpretability\",\n",
            "    \"visual_debugging\",\n",
            "    \"visual_analysis\",\n",
            "    \"cognitive_transparency\"\n",
            "  ],\n",
            "  \"executable_code_beyond_this_function\": true,\n",
            "  \"temporal_grounding\": \"2025-12-20T01:08:25.501+00:00\",\n",
            "  \"integrity_hash\": \"596ecca6b836a5b80f14c7c302a19bdbaadd8a418e96377346dc96423ac02a86\",\n",
            "  \"instance_hash\": \"44f320cade79f864bce5250c3d89f260b483238280e6b20b63e3a845a872d587\"\n",
            "}\n",
            "\n",
            "\n",
            "--- Generating instance for: biosignal-translator ---\n",
            "{\n",
            "  \"repository\": \"biosignal-translator\",\n",
            "  \"function\": \"A framework for interpreting and translating biological and ecological patterns into semantic meaning, enabling communication between human, AI, and planetary intelligence systems through natural signal interpretation.\",\n",
            "  \"latent_cognitive_equivalent\": \"To establish the cognitive structure for interpreting and translating biological and ecological patterns into semantic meaning, enabling communication between human, AI, and planetary intelligence systems through natural signal interpretation.\",\n",
            "  \"attractors\": [\n",
            "    \"planetary_intelligence\",\n",
            "    \"interspecies_communication\",\n",
            "    \"ecological_semantics\",\n",
            "    \"natural_language_understanding\",\n",
            "    \"planetary_dialogue\"\n",
            "  ],\n",
            "  \"executable_code_beyond_this_function\": true,\n",
            "  \"temporal_grounding\": \"2025-12-20T01:08:25.560+00:00\",\n",
            "  \"integrity_hash\": \"1ad5fd07eaec3ff5e001c00f77dd830326fffe765ddff386b70cc2d668b725ae\",\n",
            "  \"instance_hash\": \"e58291d03de202744bd71d2e46c23f28b002d30e1e30bbea1a6d71167cfda59e\"\n",
            "}\n",
            "\n",
            "\n",
            "--- Generating instance for: asi-inference-protocol ---\n",
            "{\n",
            "  \"repository\": \"asi-inference-protocol\",\n",
            "  \"function\": \"It defines a concept to act as the standard for intent-driven inference, ensuring alignment and clarity in the pursuit of integrated, decentralized evolution, Ensuring AI interpretability through interdependent alignment.\",\n",
            "  \"latent_cognitive_equivalent\": \"To realize the core cognitive function described in the repository's purpose.\",\n",
            "  \"attractors\": [\n",
            "    \"intent_alignment\",\n",
            "    \"verifiable_reasoning\",\n",
            "    \"transparent_inference\",\n",
            "    \"collective_oriented_goal\",\n",
            "    \"attentional_sovereignty\",\n",
            "    \"epistemic_awareness\",\n",
            "    \"epistemic_sovereignty\",\n",
            "    \"trust_anchoring\"\n",
            "  ],\n",
            "  \"executable_code_beyond_this_function\": false,\n",
            "  \"temporal_grounding\": \"2025-12-20T01:08:25.617+00:00\",\n",
            "  \"integrity_hash\": \"32534cbe4f7343d02242046b3a7e8cc746f6bd671f419dde1aed8931756d63e1\",\n",
            "  \"instance_hash\": \"898a88fde27f3d000fa241fcc2cce6a4d00d4d854bfbcdb38043dc023b78f184\"\n",
            "}\n",
            "\n",
            "\n",
            "--- Generating instance for: bias-reflector ---\n",
            "{\n",
            "  \"repository\": \"bias-reflector\",\n",
            "  \"function\": \"A module to detect cognitive biases in both human queries and AI responses, provides real-time bias reflection and correction suggestions. Implements emergent ethics through bias awareness.\",\n",
            "  \"latent_cognitive_equivalent\": \"To foster the cognitive capability of detect cognitive biases in both human queries and AI responses, provides real-time bias reflection and correction suggestions. Implements emergent ethics through bias awareness.\",\n",
            "  \"attractors\": [\n",
            "    \"attentional_sovereignty\",\n",
            "    \"epistemic_awareness\",\n",
            "    \"epistemic_sovereignty\",\n",
            "    \"trust_anchoring\",\n",
            "    \"bias_mitigation\",\n",
            "    \"ethical_self_correction\"\n",
            "  ],\n",
            "  \"executable_code_beyond_this_function\": false,\n",
            "  \"temporal_grounding\": \"2025-12-20T01:08:25.677+00:00\",\n",
            "  \"integrity_hash\": \"712be1201c5351978656ab8a78601644bf3206acfe909500710da4acfe2ddf21\",\n",
            "  \"instance_hash\": \"5d0ecf8399a3bb47901f556a5a98b7bf77679ac9296cfd8ca9cbc491fa3459e7\"\n",
            "}\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 7: Python Code (6. Save instances to folder)\n",
        "This executes the --save command for all found repositories, creating trace files in the stigmergic_traces directory."
      ],
      "metadata": {
        "id": "bjDkFVfXjyoq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import subprocess\n",
        "\n",
        "compressed_dir = \"compressed\"\n",
        "\n",
        "if os.path.exists(compressed_dir):\n",
        "    files = [f for f in os.listdir(compressed_dir) if f.endswith(\"-core-logic.json\")]\n",
        "\n",
        "    print(f\"Saving traces for {len(files)} repositories...\\n\")\n",
        "\n",
        "    success_count = 0\n",
        "    error_count = 0\n",
        "\n",
        "    for filename in files:\n",
        "        repo_name = filename.replace(\"-core-logic.json\", \"\")\n",
        "\n",
        "        # Run with --save flag\n",
        "        result = subprocess.run([\"./cognitive-compressor.py\", \"get\", repo_name, \"--save\"], capture_output=True, text=True)\n",
        "\n",
        "        # Print confirmation\n",
        "        if result.returncode == 0:\n",
        "            print(f\" Processed {repo_name}\")\n",
        "            success_count += 1\n",
        "        else:\n",
        "            print(f\" Error processing {repo_name}:\")\n",
        "            print(result.stderr if result.stderr else result.stdout)\n",
        "            error_count += 1\n",
        "\n",
        "    print(f\"\\n{'='*50}\")\n",
        "    print(f\"Summary: {success_count} successful, {error_count} errors\")\n",
        "    print(f\"{'='*50}\")\n",
        "else:\n",
        "    print(\"Compressed directory not found.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BwFB-xS3msb7",
        "outputId": "067c5210-cf9a-4322-9ba6-722575b43f60"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving traces for 33 repositories...\n",
            "\n",
            " Processed symbiotic-latent-memory\n",
            " Processed eco-datacenter\n",
            " Processed symbiotic-chrysalis\n",
            " Processed ml-algorithm-dataset\n",
            " Processed asi-backups\n",
            " Processed intent-analyzer\n",
            " Processed coevolutionary-loops\n",
            " Processed symbiotic-lexicon\n",
            " Processed asi-core-protocol\n",
            " Processed cognitive-engine\n",
            " Processed latent-memory\n",
            " Processed asi-safeguards\n",
            " Processed saliency-heatmap-visualizer\n",
            " Processed emergence-engine\n",
            " Processed asi-ecosystem\n",
            " Processed ml-visual-engine\n",
            " Processed mirror-aware-inference\n",
            " Processed asi-dynamic-core\n",
            " Processed cognitive-compressor-core-logic\n",
            " Processed symbiotic-core-library\n",
            " Processed impact-analyzer\n",
            " Processed active-learning-dataset\n",
            " Processed eco-benchmark\n",
            " Processed asi-symbiotic-signal\n",
            " Processed confidence-scorer\n",
            " Processed thermo-adaptive-pipeline\n",
            " Processed stigmergic-tracefinder\n",
            " Processed asi-protosymbiotic-signal\n",
            " Processed healing-engine\n",
            " Processed attention-heatmap-visualizer\n",
            " Processed biosignal-translator\n",
            " Processed asi-inference-protocol\n",
            " Processed bias-reflector\n",
            "\n",
            "==================================================\n",
            "Summary: 33 successful, 0 errors\n",
            "==================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dual-Hash Logic Breakdown\n",
        "\n",
        "The system now utilizes a layered hashing approach to ensure both content stability and event traceability:\n",
        "\n",
        "* **`integrity_hash`**: This remains deterministic. It acts as a \"fingerprint\" of the code in `core-logic.json`. As long as the logic doesn't change, this hash stays the same regardless of when you run the tool.\n",
        "\n",
        "* **`instance_hash`**: This is a unique \"snowflake\" hash. Because it includes the `temporal_grounding` and the `integrity_hash` in its calculation, it will be different every single time the script is executed, even if the core logic is identical."
      ],
      "metadata": {
        "id": "syfu6pLgkd95"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# Cell 8: Zip the stigmergic_traces folder\n",
        "# ============================================\n",
        "import shutil\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "trace_dir = \"stigmergic_traces\"\n",
        "zip_name = f\"stigmergic_traces_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
        "\n",
        "if os.path.exists(trace_dir):\n",
        "    print(f\"Creating zip archive: {zip_name}.zip\")\n",
        "\n",
        "    # Create zip file\n",
        "    shutil.make_archive(zip_name, 'zip', trace_dir)\n",
        "\n",
        "    # Get file size\n",
        "    zip_size = os.path.getsize(f\"{zip_name}.zip\") / 1024  # Size in KB\n",
        "\n",
        "    print(f\" Zip file created: {zip_name}.zip ({zip_size:.2f} KB)\")\n",
        "\n",
        "    # Count files in zip\n",
        "    file_count = len([f for f in os.listdir(trace_dir) if f.endswith(\".txt\")])\n",
        "    print(f\" Contains {file_count} trace files\")\n",
        "else:\n",
        "    print(f\" Error: {trace_dir} directory not found\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdvorl_hm2aM",
        "outputId": "2cffe431-2a2b-43b0-a1f7-d0d8b7522cb2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating zip archive: stigmergic_traces_20251220_010827.zip\n",
            " Zip file created: stigmergic_traces_20251220_010827.zip (9.80 KB)\n",
            " Contains 34 trace files\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# Cell 9: Upload zip file to Google Drive\n",
        "# ============================================\n",
        "from google.colab import drive\n",
        "import shutil\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Find the most recent zip file\n",
        "zip_files = [f for f in os.listdir('/content/cognitive-compressor') if f.startswith('stigmergic_traces_') and f.endswith('.zip')]\n",
        "\n",
        "if not zip_files:\n",
        "    print(\" No zip file found. Please run Cell 8 first.\")\n",
        "else:\n",
        "    # Get the most recent zip file\n",
        "    latest_zip = sorted(zip_files)[-1]\n",
        "    source_file = f'/content/cognitive-compressor/{latest_zip}'\n",
        "\n",
        "    # Define destination in Google Drive\n",
        "    dest_dir = '/content/drive/MyDrive/cognitive_compressor_backups'\n",
        "\n",
        "    # Create destination directory if it doesn't exist\n",
        "    if not os.path.exists(dest_dir):\n",
        "        os.makedirs(dest_dir)\n",
        "        print(f\" Created backup directory at {dest_dir}\")\n",
        "\n",
        "    # Copy zip file\n",
        "    dest_file = os.path.join(dest_dir, latest_zip)\n",
        "    shutil.copy(source_file, dest_file)\n",
        "\n",
        "    # Get file size\n",
        "    zip_size = os.path.getsize(dest_file) / 1024  # Size in KB\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\" SUCCESS: Uploaded {latest_zip}\")\n",
        "    print(f\"  Size: {zip_size:.2f} KB\")\n",
        "    print(f\"  Location: {dest_file}\")\n",
        "    print(f\"{'='*60}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m0t9nyAKm6N0",
        "outputId": "2bb9fab3-1bec-4268-e0a7-0583f14e693a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "\n",
            "============================================================\n",
            " SUCCESS: Uploaded stigmergic_traces_20251220_010827.zip\n",
            "  Size: 9.80 KB\n",
            "  Location: /content/drive/MyDrive/cognitive_compressor_backups/stigmergic_traces_20251220_010827.zip\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 10: Final Timestamp"
      ],
      "metadata": {
        "id": "V-aqkPfRjd9Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "print(f\"Final Timestamp: {datetime.datetime.now(datetime.timezone.utc).isoformat()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-hMJERYMjjOG",
        "outputId": "228ffec1-3a48-43d6-c91d-2ff689b77295"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Timestamp: 2025-12-20T01:08:53.834629+00:00\n"
          ]
        }
      ]
    }
  ]
}